<!DOCTYPE html><html lang="en" ><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><link href="/assets/css/syntax.css" rel="stylesheet"><title>AWS Glue Custom Output File Size And Fixed Number Of Files | The Data Guy</title><meta name="generator" content="Jekyll v4.0.0" /><meta property="og:title" content="AWS Glue Custom Output File Size And Fixed Number Of Files" /><meta name="author" content="Bhuvanesh" /><meta property="og:locale" content="en_US" /><meta name="description" content="AWS Glue parquet out files in a custom size and set the number of output files. We can use groupFiles and repartition in Glue to achieve this." /><meta property="og:description" content="AWS Glue parquet out files in a custom size and set the number of output files. We can use groupFiles and repartition in Glue to achieve this." /><meta property="og:site_name" content="The Data Guy" /><meta property="og:image" content="/assets/AWS%20Glue%20Custom%20Output%20File%20Size%20And%20Fixed%20Number%20Of%20Files.jpg" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2019-10-07T20:40:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:image" content="/assets/AWS%20Glue%20Custom%20Output%20File%20Size%20And%20Fixed%20Number%20Of%20Files.jpg" /><meta property="twitter:title" content="AWS Glue Custom Output File Size And Fixed Number Of Files" /><meta name="twitter:site" content="@bhuvithedataguy" /><meta name="twitter:creator" content="@https://twitter.com/BhuviTheDataGuy" /> <script type="application/ld+json"> {"dateModified":"2019-10-07T20:40:00+00:00","datePublished":"2019-10-07T20:40:00+00:00","image":"/assets/AWS%20Glue%20Custom%20Output%20File%20Size%20And%20Fixed%20Number%20Of%20Files.jpg","url":"/2019/10/07/aws-glue-custom-output-file-size-and-fixed-number-of-files","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/10/07/aws-glue-custom-output-file-size-and-fixed-number-of-files"},"@type":"BlogPosting","author":{"@type":"Person","name":"Bhuvanesh"},"description":"AWS Glue parquet out files in a custom size and set the number of output files. We can use groupFiles and repartition in Glue to achieve this.","headline":"AWS Glue Custom Output File Size And Fixed Number Of Files","@context":"https://schema.org"}</script><style> *,:after,:before{box-sizing:border-box;background-color:inherit;color:inherit;margin:0;padding:0}body{font-family:system-ui, sans-serif;-webkit-font-smoothing:antialiased;text-rendering:optimizeLegibility;line-height:1.7;font-size:1rem;color:#16171a}nav ul{border-right:1px solid #edf2f7}a{color:#000;text-decoration-skip-ink:auto;text-decoration:underline}pre{margin:.5rem 0;padding:.5rem}.post p{margin:.5rem 0}.post h1,.post h2,.post h3,.post h4{margin:1rem 0}.post h2:first-child,.project h2:first-child,.photo h2:first-child{margin-top:0}.meta{margin:2rem 0}code,pre{background:#ecedee}code{padding:.1rem}pre code{border:none}pre{padding:1rem;overflow-x:auto}img{max-width:100%}hr{background:#000;height:1px;border:0}header{flex-basis:10rem;flex-grow:1;position:relative}header a{text-decoration:none}header li{margin-bottom:.2rem;text-align:right;margin-right:2rem}header a.active{font-weight:bold}header,section{padding:1rem}blockquote{font-style:italic;border-left:5px solid #ececec;padding-left:1rem}h1,h2,h3,h4,h5{line-height:1;margin:1rem 0;font-weight:600}section h1:first-child{margin-top:0}strong,b{font-weight:bold}.photos ul{list-style:none}.photos li{margin-bottom:1.5rem}.photo picture,.project picture{margin-bottom:0.5rem}.posts ul,header ul{list-style:none}.posts li{align-items:center;display:flex;justify-content:space-between;margin-bottom:.5rem}.posts li a,.posts li div,.projects li a{white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.posts li time,.projects li time{padding-left:1rem;white-space:nowrap;font-variant-numeric:tabular-nums}main{display:flex;flex-wrap:wrap;max-width:60rem;margin:2rem auto;padding:1rem}@media screen and (max-width: 45rem){header li{display:inline;margin-right:1rem}.logo{padding-bottom:1rem}header ul{border-bottom:1px solid #edf2f7;padding-bottom:2rem}nav ul{border-right:0px}.photos ul{margin-top:0.5rem}}section{flex-basis:0;flex-grow:999;min-width:70%;display:flex;flex-direction:column}figcaption{font-size:smaller}#share-bar{font-size:20px}#share-bar h4{margin-bottom:10px;font-weight:500}.share-button{margin:0px;margin-bottom:10px;margin-right:3px;border:1px solid #D3D6D2;padding:5px 10px 5px 10px}.share-button:hover{opacity:1;color:#ffffff}.fa-facebook-official{color:#3b5998}.fa-facebook-official:hover{background-color:#3b5998}.fa-twitter{color:#55acee}.fa-twitter:hover{background-color:#55acee}.fa-google-plus{color:#dd4b39}.fa-google-plus:hover{background-color:#dd4b39}.fa-pinterest-p{color:#cb2027}.fa-pinterest-p:hover{background-color:#cb2027}.fa-tumblr{color:#32506d}.fa-tumblr:hover{background-color:#32506d}.fa-reddit-alien{color:#ff4500}.fa-reddit-alien:hover{background-color:#ff4500}.fa-linkedin{color:#007bb5}.fa-linkedin:hover{background-color:#007bb5}.fa-envelope{color:#444444}.fa-envelope:hover{background-color:#444444}</style></head><body><main role="main"><header role="banner"><h1 class="logo">The Data Guy</h1><div class="page-author h-card p-author"><img src="/assets/circle-cropped.png" class="author-avatar u-photo" alt="Bhuvanesh"></div><nav role="navigation"><ul><li><a href="/" >Home</a></li><li><a href="/posts/" >Posts</a></li><li><a href="/categories/" >Categories</a></li><li><a href="/tags/" >Tags</a></li><li><a href="https://medium.com/@bhuvithedataguy" >Medium Blog</a></li><li><a href="/search" >Search Here</a></li></ul></nav></header><section class="post"><h2>AWS Glue Custom Output File Size And Fixed Number Of Files</h2><p>AWS Glue is the serverless version of EMR clusters. Many organizations now adopted to use Glue for their day to day BigData workloads. I have written a blog in Searce’s Medium publication for Converting the CSV/JSON files to parquet using AWS Glue. Till now its many people are reading that and implementing on their infra. But many people are commenting about the Glue is producing a huge number for output files(converted Parquet files) in S3, even for converting 100MB of CSV file will produce 500+ Parquet files. we need to customize this output file size and number of files.</p><h2 id="why-glue-is-producing-more-small-files">Why Glue is producing more small files?</h2><p>If you are processing small chunks of files in Glue, it will read then and convert them into DynamicFrames. Glue is running on top of the Spark. So the dynamic frames will be moved to Partitions in the EMR cluster. And the Glue partition the data evenly among all of the nodes for better performance. Once its processed, all the partitions will be pushing to your target. Each partition will and one file. That’s why we are getting more files.</p><h2 id="customize-the-output-files">Customize the output files:</h2><p>We can customize it in two ways.</p><ol><li>While reading the data from the source.</li><li>While writing the data to the target.</li></ol><p>If you have so many small numbers of files in your source, them Glue process them in many partitions. So we can force the Glue to read multiple file in one shot. Like we are grouping multiple file and the Glue virtually consider this as a single file.</p><p>Else, once you processed the data, you can repartition the data. So you can mention how many partitions you want. Let’s say if you repartition the data with 5, then it’ll write 5 files in your target.</p><h2 id="testing-infra-setup">Testing Infra setup:</h2><ul><li>I have 1GB of test data set.</li><li>Format CSV</li><li>Split into 20 files.</li><li>Each file is 52MB.</li><li>Created a Glue crawler on top of this data and its created the table in Glue catalog.</li><li>Im using glue to convert this CSV to Parquet. Follow the instructions here: <a href="https://medium.com/searce/convert-csv-json-files-to-apache-parquet-using-aws-glue-a760d177b45f" title="https://medium.com/searce/convert-csv-json-files-to-apache-parquet-using-aws-glue-a760d177b45f">https://medium.com/searce/convert-csv-json-files-to-apache-parquet-using-aws-glue-a760d177b45f</a></li></ul><p><img src="/assets/AWS Glue Custom Output File Size And Fixed Number Of Files2 .jpg" alt="" /></p><h2 id="option-1-groupfiles">Option 1: groupFiles</h2><p><strong>From AWS Doc,</strong></p><blockquote><p>You can set properties of your tables to enable an AWS Glue ETL job to group files when they are read from an Amazon S3 data store. These properties enable each ETL task to read a group of input files into a single in-memory partition, this is especially useful when there is a large number of small files in your Amazon S3 data store.</p></blockquote><p><strong>groupFiles:</strong></p><p>Set <strong>groupFiles</strong> to <code class="language-html highlighter-rouge">inPartition</code> to enable the grouping of files within an Amazon S3 data partition. AWS Glue automatically enables grouping if there are more than 50,000 input files.</p><p><strong>groupSize:</strong></p><p>Set <strong>groupSize</strong> to the target size of groups in bytes. The <strong>groupSize</strong> property is optional, if not provided, AWS Glue calculates a size to use all the CPU cores in the cluster while still reducing the overall number of ETL tasks and in-memory partitions.</p><p>Go to Glue –&gt; Tables –&gt; select your table –&gt; Edit Table.</p><p>Unde the table properties, add the following parameters.</p><ul><li><code class="language-html highlighter-rouge">groupFiles</code> - <code class="language-html highlighter-rouge">inPartition</code></li><li><code class="language-html highlighter-rouge">groupSize</code> - <code class="language-html highlighter-rouge">209715200</code></li></ul><p>This will read 200MB data in one partition. Lets run the job and see the output.</p><ul><li>Total Number of files: 5</li><li>Each file size: 393kb</li></ul><p><img src="/assets/AWS Glue Custom Output File Size And Fixed Number Of Files3.jpg" alt="" /></p><h2 id="option-2-groupfiles-while-reading-from-s3">Option 2: groupFiles while reading from S3</h2><p>It’s the same as the previous one, but if you take a look at the datasource, its creating the dynamic frame from the catalog table.</p><div class="language-html highlighter-rouge"><div class="highlight"><pre class="syntax"><code>datasource0 = glueContext.create_dynamic_frame.from_catalog(database = "bhuvi"
</code></pre></div></div><p>But if you are directly reading it from S3, you can change the source like below.</p><div class="language-html highlighter-rouge"><div class="highlight"><pre class="syntax"><code>datasource0 = glueContext.create_dynamic_frame_from_options("s3", {'paths': ["s3://s3path/"], 'recurse':True, 'groupFiles': 'inPartition', 'groupSize': '104857600'}, format="csv")
</code></pre></div></div><h2 id="option-3-repartition">Option 3: Repartition</h2><p>Once the ETL process is completed, before writing it to S3, we need to repartition it. The partition size is equal to the number of files you want in s3.</p><p>My current code as below.</p><figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="n">datasource0</span> <span class="o">=</span> <span class="n">glueContext</span><span class="p">.</span><span class="n">create_dynamic_frame</span><span class="p">.</span><span class="n">from_catalog</span><span class="p">(</span><span class="n">database</span> <span class="o">=</span> <span class="s">"bhuvi"</span><span class="p">,</span> <span class="n">table_name</span> <span class="o">=</span> <span class="s">"glue_csv"</span><span class="p">,</span> <span class="n">transformation_ctx</span> <span class="o">=</span> <span class="s">"datasource0"</span><span class="p">)</span>
    <span class="n">applymapping1</span> <span class="o">=</span> <span class="n">ApplyMapping</span><span class="p">.</span><span class="nb">apply</span><span class="p">(</span><span class="n">frame</span> <span class="o">=</span> <span class="n">datasource0</span><span class="p">,</span> <span class="n">mappings</span> <span class="o">=</span> <span class="p">[(</span><span class="s">"ln"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">,</span> <span class="s">"ln"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">),</span> <span class="p">(</span><span class="s">"gender"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">,</span> <span class="s">"gender"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">),</span> <span class="p">(</span><span class="s">"ip"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">,</span> <span class="s">"ip"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">),</span> <span class="p">(</span><span class="s">"fn"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">,</span> <span class="s">"fn"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">),</span> <span class="p">(</span><span class="s">"id"</span><span class="p">,</span> <span class="s">"long"</span><span class="p">,</span> <span class="s">"id"</span><span class="p">,</span> <span class="s">"long"</span><span class="p">),</span> <span class="p">(</span><span class="s">"email"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">,</span> <span class="s">"email"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">)],</span> <span class="n">transformation_ctx</span> <span class="o">=</span> <span class="s">"applymapping1"</span><span class="p">)</span>
    <span class="n">resolvechoice2</span> <span class="o">=</span> <span class="n">ResolveChoice</span><span class="p">.</span><span class="nb">apply</span><span class="p">(</span><span class="n">frame</span> <span class="o">=</span> <span class="n">applymapping1</span><span class="p">,</span> <span class="n">choice</span> <span class="o">=</span> <span class="s">"make_struct"</span><span class="p">,</span> <span class="n">transformation_ctx</span> <span class="o">=</span> <span class="s">"resolvechoice2"</span><span class="p">)</span>
    <span class="n">dropnullfields3</span> <span class="o">=</span> <span class="n">DropNullFields</span><span class="p">.</span><span class="nb">apply</span><span class="p">(</span><span class="n">frame</span> <span class="o">=</span> <span class="n">resolvechoice2</span><span class="p">,</span> <span class="n">transformation_ctx</span> <span class="o">=</span> <span class="s">"dropnullfields3"</span><span class="p">)</span>
    <span class="n">datasink4</span> <span class="o">=</span> <span class="n">glueContext</span><span class="p">.</span><span class="n">write_dynamic_frame</span><span class="p">.</span><span class="n">from_options</span><span class="p">(</span><span class="n">frame</span> <span class="o">=</span> <span class="n">dropnullfields3</span><span class="p">,</span> <span class="n">connection_type</span> <span class="o">=</span> <span class="s">"s3"</span><span class="p">,</span> <span class="n">connection_options</span> <span class="o">=</span> <span class="p">{</span><span class="s">"path"</span><span class="p">:</span> <span class="s">"s3://bhuvi-datalake/parquet-new"</span><span class="p">},</span> <span class="nb">format</span> <span class="o">=</span> <span class="s">"parquet"</span><span class="p">,</span> <span class="n">transformation_ctx</span> <span class="o">=</span> <span class="s">"datasink4"</span><span class="p">)</span>
    <span class="n">job</span><span class="p">.</span><span class="n">commit</span><span class="p">()</span></code></pre></figure><p>Just add the repartition command above the write data frame line.</p><figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="n">datasource0</span> <span class="o">=</span> <span class="n">glueContext</span><span class="p">.</span><span class="n">create_dynamic_frame</span><span class="p">.</span><span class="n">from_catalog</span><span class="p">(</span><span class="n">database</span> <span class="o">=</span> <span class="s">"bhuvi"</span><span class="p">,</span> <span class="n">table_name</span> <span class="o">=</span> <span class="s">"glue_csv"</span><span class="p">,</span> <span class="n">transformation_ctx</span> <span class="o">=</span> <span class="s">"datasource0"</span><span class="p">)</span>
    <span class="n">applymapping1</span> <span class="o">=</span> <span class="n">ApplyMapping</span><span class="p">.</span><span class="nb">apply</span><span class="p">(</span><span class="n">frame</span> <span class="o">=</span> <span class="n">datasource0</span><span class="p">,</span> <span class="n">mappings</span> <span class="o">=</span> <span class="p">[(</span><span class="s">"ln"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">,</span> <span class="s">"ln"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">),</span> <span class="p">(</span><span class="s">"gender"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">,</span> <span class="s">"gender"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">),</span> <span class="p">(</span><span class="s">"ip"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">,</span> <span class="s">"ip"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">),</span> <span class="p">(</span><span class="s">"fn"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">,</span> <span class="s">"fn"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">),</span> <span class="p">(</span><span class="s">"id"</span><span class="p">,</span> <span class="s">"long"</span><span class="p">,</span> <span class="s">"id"</span><span class="p">,</span> <span class="s">"long"</span><span class="p">),</span> <span class="p">(</span><span class="s">"email"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">,</span> <span class="s">"email"</span><span class="p">,</span> <span class="s">"string"</span><span class="p">)],</span> <span class="n">transformation_ctx</span> <span class="o">=</span> <span class="s">"applymapping1"</span><span class="p">)</span>
    <span class="n">resolvechoice2</span> <span class="o">=</span> <span class="n">ResolveChoice</span><span class="p">.</span><span class="nb">apply</span><span class="p">(</span><span class="n">frame</span> <span class="o">=</span> <span class="n">applymapping1</span><span class="p">,</span> <span class="n">choice</span> <span class="o">=</span> <span class="s">"make_struct"</span><span class="p">,</span> <span class="n">transformation_ctx</span> <span class="o">=</span> <span class="s">"resolvechoice2"</span><span class="p">)</span>
    <span class="n">dropnullfields3</span> <span class="o">=</span> <span class="n">DropNullFields</span><span class="p">.</span><span class="nb">apply</span><span class="p">(</span><span class="n">frame</span> <span class="o">=</span> <span class="n">resolvechoice2</span><span class="p">,</span> <span class="n">transformation_ctx</span> <span class="o">=</span> <span class="s">"dropnullfields3"</span><span class="p">)</span>
    <span class="n">datasource_df</span> <span class="o">=</span> <span class="n">dropnullfields3</span><span class="p">.</span><span class="n">repartition</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">datasink4</span> <span class="o">=</span> <span class="n">glueContext</span><span class="p">.</span><span class="n">write_dynamic_frame</span><span class="p">.</span><span class="n">from_options</span><span class="p">(</span><span class="n">frame</span> <span class="o">=</span> <span class="n">datasource_df</span><span class="p">,</span> <span class="n">connection_type</span> <span class="o">=</span> <span class="s">"s3"</span><span class="p">,</span> <span class="n">connection_options</span> <span class="o">=</span> <span class="p">{</span><span class="s">"path"</span><span class="p">:</span> <span class="s">"s3://bhuvi-datalake/parquet-new"</span><span class="p">},</span> <span class="nb">format</span> <span class="o">=</span> <span class="s">"parquet"</span><span class="p">,</span> <span class="n">transformation_ctx</span> <span class="o">=</span> <span class="s">"datasink4"</span><span class="p">)</span>
    <span class="n">job</span><span class="p">.</span><span class="n">commit</span><span class="p">()</span></code></pre></figure><p><code class="language-html highlighter-rouge">repartition(2)</code> - This will create 2 files in S3.</p><ul><li>Total files: 2</li><li>Each file size: 1.7MB</li></ul><p><img src="/assets/AWS Glue Custom Output File Size And Fixed Number Of Files1.jpg" alt="" /></p><h2 id="final-words">Final words:</h2><p>From the above experiments, we can control the number of files for output and reducing the small files as output. But we can set the exact file size for output. Because Spark’s <a href="https://hackernoon.com/managing-spark-partitions-with-coalesce-and-repartition-4050c57ad5c4">coalesce and repartition</a> features are not yet implemented in Glue’s Python API, but its supports in Scala. I personally recommend using option 1.</p><h2 id="further-reading">Further Reading:</h2><p>I have found some useful information while doing this experiment. Im giving those links below.</p><ol><li><a href="https://docs.aws.amazon.com/glue/latest/dg/grouping-input-files.html">Reading Input Files in Larger Groups</a></li><li><a href="https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-connect.html#aws-glue-programming-etl-connect-s3">Connection Types and Options for ETL in AWS Glue</a></li><li><a href="https://stackoverflow.com/questions/48693943/how-to-use-aws-glue-spark-to-convert-csvs-partitioned-and-split-in-s3-to-parti">How to use AWS Glue / Spark to convert CSVs partitioned and split in S3 to partitioned and split Parquet</a></li><li><a href="https://stackoverflow.com/questions/47147159/combine-multiple-raw-files-into-single-parquet-file">Combine multiple raw files into single parquet file</a></li><li><a href="https://github.com/aws-samples/aws-glue-samples/blob/master/FAQ_and_How_to.md#aws-glue-faq-or-how-to-get-things-done">AWS Glue FAQ, or How to Get Things Done</a></li><li><a href="https://stackoverflow.com/questions/52822526/dynamicframe-vs-dataframe">DynamicFrame vs DataFrame</a></li><li><a href="https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame.html">DynamicFrame Class</a></li></ol><h2 id="some-interesting-blogs-for-you">Some interesting blogs for you:</h2><ol><li><a href="https://thedataguy.in/automate-redshift-vacuum-analyze-using-shell-script-utility/">Automate your AWS Redshift Vacuum and Analyze with Scripts</a></li><li><a href="https://thedataguy.in/export-redshift-system-tables-views-to-s3/">Export RedShift system tables to S3</a></li></ol><span class="meta"><time datetime="2019-10-07T20:40:00+00:00">October 7, 2019</time> &middot; <a href="/tags/#aws">aws</a>, <a href="/tags/#glue">glue</a>, <a href="/tags/#parquet">parquet</a>, <a href="/tags/#s3">s3</a></span><hr> <!--<span class="meta"><time datetime="2019-10-07T20:40:00+00:00">October 7, 2019</time> &middot; <a class="post" href="/tag/aws">aws</a>, <a class="post" href="/tag/glue">glue</a>, <a class="post" href="/tag/parquet">parquet</a>, <a class="post" href="/tag/s3">s3</a></span> --></section></main></body></html>
