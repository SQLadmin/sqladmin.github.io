<!DOCTYPE html><html lang="en" ><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><link href="/assets/css/syntax.css" rel="stylesheet"><title>Debezium MySQL Snapshot From Read Replica And Resume From Master | The Data Guy</title><meta name="generator" content="Jekyll v4.0.0" /><meta property="og:title" content="Debezium MySQL Snapshot From Read Replica And Resume From Master" /><meta name="author" content="Bhuvanesh" /><meta property="og:locale" content="en_US" /><meta name="description" content="Debezium MySQL connector to take snapshot from Read replica and then point it to the Master node without GTID. We can resume the CDC with binlog information from slave status." /><meta property="og:description" content="Debezium MySQL connector to take snapshot from Read replica and then point it to the Master node without GTID. We can resume the CDC with binlog information from slave status." /><meta property="og:site_name" content="The Data Guy" /><meta property="og:image" content="/assets/Debezium%20MySQL%20Snapshot%20From%20Read%20Replica%20Without%20GTID%20-%20Custom%20Binlog.jpg" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2019-12-31T12:10:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:image" content="/assets/Debezium%20MySQL%20Snapshot%20From%20Read%20Replica%20Without%20GTID%20-%20Custom%20Binlog.jpg" /><meta property="twitter:title" content="Debezium MySQL Snapshot From Read Replica And Resume From Master" /><meta name="twitter:site" content="@bhuvithedataguy" /><meta name="twitter:creator" content="@https://twitter.com/BhuviTheDataGuy" /> <script type="application/ld+json"> {"dateModified":"2019-12-31T12:10:00+00:00","datePublished":"2019-12-31T12:10:00+00:00","image":"/assets/Debezium%20MySQL%20Snapshot%20From%20Read%20Replica%20Without%20GTID%20-%20Custom%20Binlog.jpg","url":"/2019/12/31/debezium-mysql-snapshot-from-read-replica-and-resume-from-master","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/12/31/debezium-mysql-snapshot-from-read-replica-and-resume-from-master"},"@type":"BlogPosting","author":{"@type":"Person","name":"Bhuvanesh"},"description":"Debezium MySQL connector to take snapshot from Read replica and then point it to the Master node without GTID. We can resume the CDC with binlog information from slave status.","headline":"Debezium MySQL Snapshot From Read Replica And Resume From Master","@context":"https://schema.org"}</script><style> *,:after,:before{box-sizing:border-box;background-color:inherit;color:inherit;margin:0;padding:0}body{font-family:system-ui, sans-serif;-webkit-font-smoothing:antialiased;text-rendering:optimizeLegibility;line-height:1.7;font-size:1rem;color:#16171a}nav ul{border-right:1px solid #edf2f7}a{color:#000;text-decoration-skip-ink:auto;text-decoration:underline}pre{margin:.5rem 0;padding:.5rem}.post p{margin:.5rem 0}.post h1,.post h2,.post h3,.post h4{margin:1rem 0}.post h2:first-child,.project h2:first-child,.photo h2:first-child{margin-top:0}.meta{margin:2rem 0}code,pre{background:#ecedee}code{padding:.1rem}pre code{border:none}pre{padding:1rem;overflow-x:auto}img{max-width:100%}hr{background:#000;height:1px;border:0}header{flex-basis:10rem;flex-grow:1;position:relative}header a{text-decoration:none}header li{margin-bottom:.2rem;text-align:right;margin-right:2rem}header a.active{font-weight:bold}header,section{padding:1rem}blockquote{font-style:italic;border-left:5px solid #ececec;padding-left:1rem}h1,h2,h3,h4,h5{line-height:1;margin:1rem 0;font-weight:600}section h1:first-child{margin-top:0}strong,b{font-weight:bold}.photos ul{list-style:none}.photos li{margin-bottom:1.5rem}.photo picture,.project picture{margin-bottom:0.5rem}.posts ul,header ul{list-style:none}.posts li{align-items:center;display:flex;justify-content:space-between;margin-bottom:.5rem}.posts li a,.posts li div,.projects li a{white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.posts li time,.projects li time{padding-left:1rem;white-space:nowrap;font-variant-numeric:tabular-nums}main{display:flex;flex-wrap:wrap;max-width:60rem;margin:2rem auto;padding:1rem}@media screen and (max-width: 45rem){header li{display:inline;margin-right:1rem}.logo{padding-bottom:1rem}header ul{border-bottom:1px solid #edf2f7;padding-bottom:2rem}nav ul{border-right:0px}.photos ul{margin-top:0.5rem}}section{flex-basis:0;flex-grow:999;min-width:70%;display:flex;flex-direction:column}figcaption{font-size:smaller}#share-bar{font-size:20px}#share-bar h4{margin-bottom:10px;font-weight:500}.share-button{margin:0px;margin-bottom:10px;margin-right:3px;border:1px solid #D3D6D2;padding:5px 10px 5px 10px}.share-button:hover{opacity:1;color:#ffffff}.fa-facebook-official{color:#3b5998}.fa-facebook-official:hover{background-color:#3b5998}.fa-twitter{color:#55acee}.fa-twitter:hover{background-color:#55acee}.fa-google-plus{color:#dd4b39}.fa-google-plus:hover{background-color:#dd4b39}.fa-pinterest-p{color:#cb2027}.fa-pinterest-p:hover{background-color:#cb2027}.fa-tumblr{color:#32506d}.fa-tumblr:hover{background-color:#32506d}.fa-reddit-alien{color:#ff4500}.fa-reddit-alien:hover{background-color:#ff4500}.fa-linkedin{color:#007bb5}.fa-linkedin:hover{background-color:#007bb5}.fa-envelope{color:#444444}.fa-envelope:hover{background-color:#444444}</style></head><body><main role="main"><header role="banner"><h1 class="logo">The Data Guy</h1><div class="page-author h-card p-author"><img src="/assets/circle-cropped.png" class="author-avatar u-photo" alt="Bhuvanesh"></div><nav role="navigation"><ul><li><a href="/" >Home</a></li><li><a href="/posts/" >Posts</a></li><li><a href="/categories/" >Categories</a></li><li><a href="/tags/" >Tags</a></li><li><a href="https://medium.com/@bhuvithedataguy" >Medium Blog</a></li><li><a href="/search" >Search Here</a></li></ul></nav></header><section class="post"><h2>Debezium MySQL Snapshot From Read Replica And Resume From Master</h2><p>In my <a href="https://thedataguy.in/debezium-mysql-snapshot-from-read-replica-with-gtid/">previous post</a>, I have shown you how to take the snapshot from Read Replica with GTID for Debezium MySQL connector. GTID concept is awesome, but still many of us using the replication without GTID. For these cases, we can take a snapshot from Read replica and then manually push the Master binlog information to the offsets topic. Injecting manual entry for offsets topic is <a href="https://debezium.io/documentation/faq/#how_to_change_the_offsets_of_the_source_database">already documented in Debezium</a>. Iâ€™m just guiding you the way to take snapshot from Read replica without GTID.</p><h2 id="requirements">Requirements:</h2><ul><li>Setup master slave replication.</li><li>The slave must have <code class="language-html highlighter-rouge">log-slave-updates=ON</code> else connector will fail to read from beginning onwards.</li><li>Debezium connector should be able to access the Read replica with a user that is having necessary permissions.</li><li>Install Debezium connector.</li></ul><h2 id="use-a-different-name-for-slave-binlog">Use a different name for Slave binlog:</h2><blockquote><p><strong>Note</strong>: If you are already having a Master slave setup then ignore this step.</p></blockquote><p>By default, MySQL use <code class="language-html highlighter-rouge">mysql-bin</code> as a prefix for all the mysql binlog files. We should not have the same binlog name for both the master and the slave. If you are setting up a new master-slave replication then make this change in <code class="language-html highlighter-rouge">my.cnf</code> file.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">master#
log_bin <span class="o">=</span> /var/log/mysql/mysql-bin.log
slave#
log_bin <span class="o">=</span> /var/log/mysql/mysql-slave-bin.log</code></pre></figure><h2 id="sample-data">Sample data:</h2><p>Create a new database to test this sync and insert some values.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">create database bhuvi<span class="p">;</span>
use bhuvi<span class="p">;</span>
create table rohi <span class="o">(</span>
<span class="nb">id </span>int,
fn varchar<span class="o">(</span>10<span class="o">)</span>,
<span class="nb">ln </span>varchar<span class="o">(</span>10<span class="o">)</span>,
phone int<span class="o">)</span><span class="p">;</span>

insert into rohi values <span class="o">(</span>1, <span class="s1">'rohit'</span>, <span class="s1">'last'</span>,87611<span class="o">)</span><span class="p">;</span>
insert into rohi values <span class="o">(</span>2, <span class="s1">'rohit'</span>, <span class="s1">'last'</span>,87611<span class="o">)</span><span class="p">;</span>
insert into rohi values <span class="o">(</span>3, <span class="s1">'rohit'</span>, <span class="s1">'last'</span>,87611<span class="o">)</span><span class="p">;</span>
insert into rohi values <span class="o">(</span>4, <span class="s1">'rohit'</span>, <span class="s1">'last'</span>,87611<span class="o">)</span><span class="p">;</span>
insert into rohi values <span class="o">(</span>5, <span class="s1">'rohit'</span>, <span class="s1">'last'</span>,87611<span class="o">)</span><span class="p">;</span></code></pre></figure><h3 id="create-the-mysql-connector-config">Create the MySQL Connector Config:</h3><p>File Name: mysql.json</p><figure class="highlight"><pre><code class="language-json" data-lang="json"><span class="p">{</span><span class="w">
</span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-connector-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"config"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-connector-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"connector.class"</span><span class="p">:</span><span class="w"> </span><span class="s2">"io.debezium.connector.mysql.MySqlConnector"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.server.id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1"</span><span class="p">,</span><span class="w">
</span><span class="nl">"tasks.max"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.history.kafka.bootstrap.servers"</span><span class="p">:</span><span class="w"> </span><span class="s2">"YOUR-BOOTSTRAP-SERVER:9092"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.history.kafka.topic"</span><span class="p">:</span><span class="w"> </span><span class="s2">"schema-changes.mysql"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.server.name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.hostname"</span><span class="p">:</span><span class="w"> </span><span class="s2">"IP-OF-READER-NODE"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.port"</span><span class="p">:</span><span class="w"> </span><span class="s2">"3306"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.user"</span><span class="p">:</span><span class="w"> </span><span class="s2">"bhuvi"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.password"</span><span class="p">:</span><span class="w"> </span><span class="s2">"****"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.whitelist"</span><span class="p">:</span><span class="w"> </span><span class="s2">"bhuvi"</span><span class="p">,</span><span class="w">
</span><span class="nl">"snapshot.mode"</span><span class="p">:</span><span class="w"> </span><span class="s2">"initial"</span><span class="p">,</span><span class="w">
</span><span class="nl">"snapshot.locking.mode"</span><span class="p">:</span><span class="w"> </span><span class="s2">"none"</span><span class="p">,</span><span class="w">
</span><span class="nl">"key.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"value.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"key.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"value.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.key.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.value.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.key.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.value.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms"</span><span class="p">:</span><span class="w"> </span><span class="s2">"unwrap"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms.unwrap.add.source.fields"</span><span class="p">:</span><span class="w"> </span><span class="s2">"ts_ms"</span><span class="p">,</span><span class="w">
</span><span class="nl">"tombstones.on.delete"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms.unwrap.type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"io.debezium.transforms.ExtractNewRecordState
}
}</span></code></pre></figure><p>Run the below command to register the mysql connector.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">curl <span class="nt">-X</span> POST <span class="nt">-H</span> <span class="s2">"Accept: application/json"</span> <span class="nt">-H</span> <span class="s2">"Content-Type: application/json"</span> http://localhost:8083/connectors <span class="nt">-d</span> @mysql.json</code></pre></figure><p>Once the snapshot has been done, then itâ€™ll push the binlog information of the Slave while taking the snapshot. And then itâ€™ll start to continue to do CDC for the upcoming data. You will see the first record in your <code class="language-html highlighter-rouge">connect-offsets</code> topic as like below.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"ip-172-31-25-99-bin.000002"</span>,<span class="s2">"pos"</span>:7240<span class="o">}</span></code></pre></figure><p>Then for continuous replication, itâ€™ll start adding the record to this topic along with some more addition metadata like, server id, timestamp.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">{</span><span class="s2">"ts_sec"</span>:1577764293,<span class="s2">"file"</span>:<span class="s2">"ip-172-31-25-99-bin.000002"</span>,<span class="s2">"pos"</span>:7305,<span class="s2">"row"</span>:1,<span class="s2">"server_id"</span>:1,<span class="s2">"event"</span>:2<span class="o">}</span></code></pre></figure><p>You can monitor the snapshot progress from JMX.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">curl localhost:7071 | <span class="nb">grep </span>debezium_metrics_SecondsBehindMaster
debezium_metrics_SecondsBehindMaster<span class="o">{</span><span class="nv">context</span><span class="o">=</span><span class="s2">"binlog"</span>,name<span class="o">=</span><span class="s2">"mysql-db01"</span>,plugin<span class="o">=</span><span class="s2">"mysql"</span>,<span class="o">}</span> 299.577536699E9</code></pre></figure><p>Sometimes the metrics take a few more minutes to update. So once you are able to see the last binlog information from the <code class="language-html highlighter-rouge">connet-offsets</code> and from JMX the <code class="language-html highlighter-rouge">lag <span class="nt">&lt;10</span></code>, then the snapshot is done.</p><h2 id="switch-to-master">Switch to Master:</h2><p>Before switching to the master, we need to stop the slave instance to get the consistent binlog information of Master from the Read replica. And then stop the Debezium connector to update binlog information manually in the <code class="language-html highlighter-rouge">connect-offsets</code> topic.</p><figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="n">mysql</span><span class="o">-</span><span class="n">slave</span><span class="o">&gt;</span> <span class="n">stop</span> <span class="n">slave</span><span class="p">;</span></code></pre></figure><figure class="highlight"><pre><code class="language-shell" data-lang="shell">Debezium-connector-node# systemctl stop confluent-connect-distributed</code></pre></figure><p>To simulate the real-time scenario, we can add 1 new row in our MySQL table. So this will never replicate to your slave. But once you switch the node, it should start reading from this row.</p><figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="n">mysql</span><span class="o">-</span><span class="n">master</span><span class="o">&gt;</span> <span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="s1">'87611'</span><span class="p">);</span></code></pre></figure><p>Also create a new table and insert one new row to this new table.</p><figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="n">mysql</span><span class="o">-</span><span class="n">master</span><span class="o">&gt;</span> <span class="k">create</span> <span class="k">table</span> <span class="n">testtbl</span> <span class="p">(</span><span class="n">id</span> <span class="nb">int</span><span class="p">);</span>
<span class="n">mysql</span><span class="o">-</span><span class="n">master</span><span class="o">&gt;</span> <span class="k">insert</span> <span class="k">into</span> <span class="n">testtbl</span> <span class="k">values</span> <span class="p">(</span><span class="mi">1</span><span class="p">);</span></code></pre></figure><p>Once the switchover has been done, then it should read the <code class="language-html highlighter-rouge">6'th row</code> that we inserted and a new topic should be created for the <code class="language-html highlighter-rouge">testtbl</code></p><h2 id="get-the-last-binlog-info-from-offsets">Get the last binlog info from offsets:</h2><p>Install <code class="language-html highlighter-rouge">kafkacat</code> in you broker node. (itâ€™s available from <a href="https://docs.confluent.io/current/app-development/kafkacat-usage.html">confluent repo</a>)</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">apt-get <span class="nb">install </span>kafkacat</code></pre></figure><p>Run the below command get the last read binlog info.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafkacat <span class="nt">-b</span> localhost:9092 <span class="nt">-C</span> <span class="nt">-t</span> connect-offsets  <span class="nt">-f</span> <span class="s1">'Partition(%p) %k %s\n'</span></code></pre></figure><ul><li><strong>-b</strong> - Broker</li><li><strong>-C</strong> consumer</li><li><strong>-t</strong> Topic</li><li><strong>-f</strong> lag takes arguments specifying both the format of the output and the fields to include.</li></ul><p>You will get something like this.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">Partition<span class="o">(</span>0<span class="o">)</span> <span class="o">[</span><span class="s2">"mysql-connector-db01"</span>,<span class="o">{</span><span class="s2">"server"</span>:<span class="s2">"mysql-db01"</span><span class="o">}]</span> <span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"ip-172-31-25-99-bin.000002"</span>,<span class="s2">"pos"</span>:7240<span class="o">}</span>
Partition<span class="o">(</span>0<span class="o">)</span> <span class="o">[</span><span class="s2">"mysql-connector-db01"</span>,<span class="o">{</span><span class="s2">"server"</span>:<span class="s2">"mysql-db01"</span><span class="o">}]</span> <span class="o">{</span><span class="s2">"ts_sec"</span>:1577764293,<span class="s2">"file"</span>:<span class="s2">"ip-172-31-25-99-bin.000002"</span>,<span class="s2">"pos"</span>:7305,<span class="s2">"row"</span>:1,<span class="s2">"server_id"</span>:1,<span class="s2">"event"</span>:2<span class="o">}</span></code></pre></figure><ul><li><code class="language-html highlighter-rouge">Partition(0)</code> - The Partition where the information is location.</li><li><code class="language-html highlighter-rouge">mysql-connector-db01</code> Connector Name</li><li><code class="language-html highlighter-rouge">"server":"mysql-db01"</code> Server name that the connect has.</li><li><code class="language-html highlighter-rouge">"ts-sec":1577764293,"file":"ip-172-31-25-99-bin.000002","pos":7305,"row":1,"server_id":1,"event":2</code> - Binlog information</li></ul><p>Now weâ€™ll manually push a new record inside this topic with the same information but just replace the binlog file name and its position. We need to continue the CDC where it stopped, so the get the exact starting binlog information weâ€™ll use <code class="language-html highlighter-rouge">slave status</code> from the Read replica.</p><figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="n">mysql</span><span class="o">-</span><span class="n">slave</span><span class="o">&gt;</span> <span class="k">show</span> <span class="n">slave</span> <span class="n">status</span><span class="err">\</span><span class="k">G</span>

                   <span class="n">Slave_IO_State</span><span class="p">:</span>
                      <span class="n">Master_Host</span><span class="p">:</span> <span class="mi">172</span><span class="p">.</span><span class="mi">31</span><span class="p">.</span><span class="mi">36</span><span class="p">.</span><span class="mi">115</span>
                      <span class="n">Master_User</span><span class="p">:</span> <span class="n">bhuvi</span>
                      <span class="n">Master_Port</span><span class="p">:</span> <span class="mi">3306</span>
                    <span class="n">Connect_Retry</span><span class="p">:</span> <span class="mi">60</span>
                  <span class="n">Master_Log_File</span><span class="p">:</span> <span class="n">mysql</span><span class="o">-</span><span class="n">bin</span><span class="p">.</span><span class="mi">000003</span>
              <span class="n">Read_Master_Log_Pos</span><span class="p">:</span> <span class="mi">7759</span>
                   <span class="n">Relay_Log_File</span><span class="p">:</span> <span class="n">ip</span><span class="o">-</span><span class="mi">172</span><span class="o">-</span><span class="mi">31</span><span class="o">-</span><span class="mi">25</span><span class="o">-</span><span class="mi">99</span><span class="o">-</span><span class="n">relay</span><span class="o">-</span><span class="n">bin</span><span class="p">.</span><span class="mi">000009</span>
                    <span class="n">Relay_Log_Pos</span><span class="p">:</span> <span class="mi">7646</span>
              <span class="n">Exec_Master_Log_Pos</span><span class="p">:</span> <span class="mi">7759</span></code></pre></figure><p>Make a note of <code class="language-html highlighter-rouge">Master-log-file</code> and <code class="language-html highlighter-rouge">Exec-Master-Log-Pos</code> from the slave status. Now inject a new record to the offets topic.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nb">echo</span> <span class="s1">'["mysql-connector-db01",{"server":"mysql-db01"}]|{"file":"mysql-bin.000003","pos":7759}'</span> |<span class="se">\</span>
kafkacat <span class="nt">-P</span> <span class="nt">-b</span> localhost:9092 <span class="nt">-t</span> connect-offsets <span class="nt">-K</span><span class="se">\ </span>| <span class="nt">-p</span> 0</code></pre></figure><ul><li><strong>-b</strong> Broker</li><li><strong>-P</strong> Producer</li><li><strong>-K</strong> Delimiter</li><li><strong>-p</strong> Partition</li></ul><p>If you read the data from this topic, youâ€™ll see the manually injected record.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafka-console-consumer <span class="nt">--bootstrap-server</span> localhost:9092 <span class="nt">--topic</span> connect-offsets <span class="nt">--from-beginning</span>

<span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"ip-172-31-25-99-bin.000002"</span>,<span class="s2">"pos"</span>:7240<span class="o">}</span>
<span class="o">{</span><span class="s2">"ts_sec"</span>:1577764293,<span class="s2">"file"</span>:<span class="s2">"ip-172-31-25-99-bin.000002"</span>,<span class="s2">"pos"</span>:7305,<span class="s2">"row"</span>:1,<span class="s2">"server_id"</span>:1,<span class="s2">"event"</span>:2<span class="o">}</span>
<span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"mysql-bin.000003"</span>,<span class="s2">"pos"</span>:7759<span class="o">}</span></code></pre></figure><p>Once you start the Debezium MySQL connector, then itâ€™ll start reading from the slave but itâ€™ll start looking for the binlog file <code class="language-html highlighter-rouge">mysql-bin.000003</code> If you use the same binlog file name for both master and slave, then itâ€™ll be a problem. So we can do any one of the following method to solve this.</p><ol><li>Use different naming conversion for both Master and Slave binlog files.</li><li>Delete all the binlog files from the Slave using <code class="language-html highlighter-rouge">Reset master</code> command.</li><li>If the binlog file in slave is having a file named as <code class="language-html highlighter-rouge">mysql-bin.000003</code> then delete this file alone.</li><li>If the binlog file in slave is having a file names as <code class="language-html highlighter-rouge">mysql-bin.000003</code> then rename this file as <code class="language-html highlighter-rouge">mysql-bin.000003.old</code></li></ol><blockquote><p><strong>Disclaimer</strong>: Please consider with your DBA before performing any of the above steps. I recommend using step 1 or 4.</p></blockquote><h3 id="start-the-debezium-connector">Start the debezium connector:</h3><figure class="highlight"><pre><code class="language-shell" data-lang="shell">Debezium-connector-node#  systemctl start confluent-connect-distributedv</code></pre></figure><p>You in your connector log file, you can see there is an error indicating that the Debezium is not able to find the binlog file called <code class="language-html highlighter-rouge">mysql-bin.000003</code>.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="se">\[</span>2019-12-31 03:55:17,128<span class="se">\]</span> INFO WorkerSourceTask<span class="o">{</span><span class="nb">id</span><span class="o">=</span>mysql-connector-db01-0<span class="o">}</span> flushing 0 outstanding messages <span class="k">for </span>offset commit <span class="o">(</span>org.apache.kafka.connect.runtime.WorkerSourceTask<span class="o">)</span>
<span class="se">\[</span>2019-12-31 03:55:17,131<span class="se">\]</span> ERROR WorkerSourceTask<span class="o">{</span><span class="nb">id</span><span class="o">=</span>mysql-connector-db01-0<span class="o">}</span> Task threw an uncaught and unrecoverable exception <span class="o">(</span>org.apache.kafka.connect.runtime.WorkerTask<span class="o">)</span>
org.apache.kafka.connect.errors.ConnectException: The connector is trying to <span class="nb">read </span>binlog starting at binlog file <span class="s1">'mysql-bin.000003'</span>, <span class="nv">pos</span><span class="o">=</span>7759, skipping 2 events plus 1 rows, but this is no longer available on the server. Reconfigure the connector to use a snapshot when needed.
at io.debezium.connector.mysql.MySqlConnectorTask.start<span class="o">(</span>MySqlConnectorTask.java:132<span class="o">)</span>
at io.debezium.connector.common.BaseSourceTask.start<span class="o">(</span>BaseSourceTask.java:49<span class="o">)</span>
at org.apache.kafka.connect.runtime.WorkerSourceTask.execute<span class="o">(</span>WorkerSourceTask.java:208<span class="o">)</span>
at org.apache.kafka.connect.runtime.WorkerTask.doRun<span class="o">(</span>WorkerTask.java:177<span class="o">)</span>
at org.apache.kafka.connect.runtime.WorkerTask.run<span class="o">(</span>WorkerTask.java:227<span class="o">)</span>
at java.base/java.util.concurrent.Executors<span class="nv">$RunnableAdapter</span>.call<span class="o">(</span>Executors.java:515<span class="o">)</span>
at java.base/java.util.concurrent.FutureTask.run<span class="o">(</span>FutureTask.java:264<span class="o">)</span>
at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker<span class="o">(</span>ThreadPoolExecutor.java:1128<span class="o">)</span>
at java.base/java.util.concurrent.ThreadPoolExecutor<span class="nv">$Worker</span>.run<span class="o">(</span>ThreadPoolExecutor.java:628<span class="o">)</span>
at java.base/java.lang.Thread.run<span class="o">(</span>Thread.java:834<span class="o">)</span>
<span class="se">\[</span>2019-12-31 03:55:17,132<span class="se">\]</span> ERROR WorkerSourceTask<span class="o">{</span><span class="nb">id</span><span class="o">=</span>mysql-connector-db01-0<span class="o">}</span> Task is being killed and will not recover <span class="k">until </span>manually restarted <span class="o">(</span>org.apache.kafka.connect.runtime.WorkerTask<span class="o">)</span>
<span class="se">\[</span>2019-12-31 03:55:17,132<span class="se">\]</span> INFO Stopping MySQL connector task <span class="o">(</span>io.debezium.connector.mysql.MySqlConnectorTask<span class="o">)</span></code></pre></figure><p>Now we need to update the existing MySQL connectorâ€™s config and just change the <code class="language-html highlighter-rouge">"database.hostname"</code> parameter.</p><blockquote><p><strong>Note</strong>: this JSON file format is different from the one which we used to register the connector. So make sure the syntax.</p></blockquote><p><strong><em>File Name</em></strong>: mysql-update.json</p><figure class="highlight"><pre><code class="language-json" data-lang="json"><span class="p">{</span><span class="w">
</span><span class="nl">"connector.class"</span><span class="p">:</span><span class="w"> </span><span class="s2">"io.debezium.connector.mysql.MySqlConnector"</span><span class="p">,</span><span class="w">
</span><span class="nl">"snapshot.locking.mode"</span><span class="p">:</span><span class="w"> </span><span class="s2">"none"</span><span class="p">,</span><span class="w">
</span><span class="nl">"tasks.max"</span><span class="p">:</span><span class="w"> </span><span class="s2">"3"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.history.kafka.topic"</span><span class="p">:</span><span class="w"> </span><span class="s2">"schema-changes.mysql"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms"</span><span class="p">:</span><span class="w"> </span><span class="s2">"unwrap"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.key.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms.unwrap.add.source.fields"</span><span class="p">:</span><span class="w"> </span><span class="s2">"ts_ms"</span><span class="p">,</span><span class="w">
</span><span class="nl">"tombstones.on.delete"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms.unwrap.type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"io.debezium.transforms.ExtractNewRecordState"</span><span class="p">,</span><span class="w">
</span><span class="nl">"value.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.whitelist"</span><span class="p">:</span><span class="w"> </span><span class="s2">"bhuvi"</span><span class="p">,</span><span class="w">
</span><span class="nl">"key.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.user"</span><span class="p">:</span><span class="w"> </span><span class="s2">"bhuvi"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.server.id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.history.kafka.bootstrap.servers"</span><span class="p">:</span><span class="w"> </span><span class="s2">"YOUR-KAFKA-BOOTSTRAP-SERVER:9092"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.server.name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.port"</span><span class="p">:</span><span class="w"> </span><span class="s2">"3306"</span><span class="p">,</span><span class="w">
</span><span class="nl">"key.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.key.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.hostname"</span><span class="p">:</span><span class="w"> </span><span class="s2">"MASTER-IP-ADDRESS"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.password"</span><span class="p">:</span><span class="w"> </span><span class="s2">"****"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.value.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-connector-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"value.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.value.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"snapshot.mode"</span><span class="p">:</span><span class="w"> </span><span class="s2">"initial"</span><span class="w">
</span><span class="p">}</span></code></pre></figure><p>Run the below command to update the config file.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">curl <span class="nt">-X</span> PUT <span class="nt">-H</span> <span class="s2">"Accept: application/json"</span> <span class="nt">-H</span> <span class="s2">"Content-Type: application/json"</span> http://localhost:8083/connectors/mysql-connector-db01/config <span class="nt">-d</span> @mysql-update.json</code></pre></figure><p>Once the update is done, immediately itâ€™ll start connecting to the master and start reading the binlog file <code class="language-html highlighter-rouge">mysql-bin.000003</code> from position <code class="language-html highlighter-rouge">7759</code>.</p><p>We inserted a new record to the <code class="language-html highlighter-rouge">rohi</code> table. If you read this topic then you can see the row has been read. Also start inserting few more rows to this table with id 7 and 8.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafka-console-consumer <span class="nt">--bootstrap-server</span> localhost:9092 <span class="nt">--topic</span> mysql-db01.bhuvi.rohi <span class="nt">--from-beginning</span>

<span class="o">{</span><span class="s2">"id"</span>:6,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:1577788740000<span class="o">}</span>
<span class="o">{</span><span class="s2">"id"</span>:7,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:1577788764000<span class="o">}</span>
<span class="o">{</span><span class="s2">"id"</span>:8,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:1577788767000<span class="o">}</span></code></pre></figure><p>Also, it should added the <code class="language-html highlighter-rouge">testtbl</code> to the kafka topic.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafka-topics <span class="nt">--zookeeper</span> localhost:2181 <span class="nt">--list</span>

connect-configs
connect-offsets
connect-status
default_ksql_processing_log
my_connect_offsets
mysql-db01
mysql-db01.bhuvi.rohi
mysql-db01.bhuvi.testtbl
schema-changes.mysql</code></pre></figure><p>Once your switchover is done, resume the replication on your slave.</p><h3 id="debezium-series-blogs">Debezium Series blogs:</h3><ol><li><a href="https://thedataguy.in/build-production-grade-debezium-with-confluent-kafka-cluster/">Build Production Grade Debezium Cluster With Confluent Kafka</a></li><li><a href="https://thedataguy.in/monitor-debezium-mysql-connector-with-prometheus-and-grafana/">Monitor Debezium MySQL Connector With Prometheus And Grafana</a></li><li><a href="https://thedataguy.in/debezium-mysql-snapshot-from-read-replica-with-gtid/">Debezium MySQL Snapshot From Read Replica With GTID</a></li><li><a href="https://thedataguy.in/debezium-mysql-snapshot-from-read-replica-and-resume-from-master/">Debezium MySQL Snapshot From Read Replica And Resume From Master</a></li><li><a href="https://thedataguy.in/debezium-mysql-snapshot-for-aws-rds-aurora-from-backup-snaphot/">Debezium MySQL Snapshot For AWS RDS Aurora From Backup Snaphot</a></li><li><a href="https://medium.com/searce/realtime-cdc-from-mysql-using-aws-msk-with-debezium-28da5a4ca873">RealTime CDC From MySQL Using AWS MSK With Debezium</a></li></ol><span class="meta"><time datetime="2019-12-31T12:10:00+00:00">December 31, 2019</time> &middot; <a href="/tags/#kafka">kafka</a>, <a href="/tags/#mysql">mysql</a>, <a href="/tags/#debezium">debezium</a>, <a href="/tags/#replication">replication</a></span><hr> <!--<span class="meta"><time datetime="2019-12-31T12:10:00+00:00">December 31, 2019</time> &middot; <a class="post" href="/tag/kafka">kafka</a>, <a class="post" href="/tag/mysql">mysql</a>, <a class="post" href="/tag/debezium">debezium</a>, <a class="post" href="/tag/replication">replication</a></span> --></section></main></body></html>
