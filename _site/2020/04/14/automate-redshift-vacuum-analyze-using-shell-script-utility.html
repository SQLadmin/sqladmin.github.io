<!DOCTYPE html><html lang="en" ><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><link href="/assets/css/syntax.css" rel="stylesheet"><title>Automate RedShift Vacuum And Analyze with Script | The Data Guy</title><meta name="generator" content="Jekyll v4.0.0" /><meta property="og:title" content="Automate RedShift Vacuum And Analyze with Script" /><meta name="author" content="Bhuvanesh" /><meta property="og:locale" content="en_US" /><meta name="description" content="Automate the RedShift vacuum and analyze using the shell script utility" /><meta property="og:description" content="Automate the RedShift vacuum and analyze using the shell script utility" /><meta property="og:site_name" content="The Data Guy" /><meta property="og:image" content="/assets/Automate%20RedShift%20Vacuum%20And%20Analyze%20Like%20a%20Boss.jpg" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-04-14T01:15:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:image" content="/assets/Automate%20RedShift%20Vacuum%20And%20Analyze%20Like%20a%20Boss.jpg" /><meta property="twitter:title" content="Automate RedShift Vacuum And Analyze with Script" /><meta name="twitter:site" content="@bhuvithedataguy" /><meta name="twitter:creator" content="@https://twitter.com/BhuviTheDataGuy" /> <script type="application/ld+json"> {"dateModified":"2020-04-14T01:15:00+00:00","datePublished":"2020-04-14T01:15:00+00:00","image":"/assets/Automate%20RedShift%20Vacuum%20And%20Analyze%20Like%20a%20Boss.jpg","url":"/2020/04/14/automate-redshift-vacuum-analyze-using-shell-script-utility","mainEntityOfPage":{"@type":"WebPage","@id":"/2020/04/14/automate-redshift-vacuum-analyze-using-shell-script-utility"},"@type":"BlogPosting","author":{"@type":"Person","name":"Bhuvanesh"},"description":"Automate the RedShift vacuum and analyze using the shell script utility","headline":"Automate RedShift Vacuum And Analyze with Script","@context":"https://schema.org"}</script><style> *,:after,:before{box-sizing:border-box;background-color:inherit;color:inherit;margin:0;padding:0}body{font-family:system-ui, sans-serif;-webkit-font-smoothing:antialiased;text-rendering:optimizeLegibility;line-height:1.7;font-size:1rem;color:#16171a}nav ul{border-right:1px solid #edf2f7}a{color:#000;text-decoration-skip-ink:auto;text-decoration:underline}pre{margin:.5rem 0;padding:.5rem}.post p{margin:.5rem 0}.post h1,.post h2,.post h3,.post h4{margin:1rem 0}.post h2:first-child,.project h2:first-child,.photo h2:first-child{margin-top:0}.meta{margin:2rem 0}code,pre{background:#ecedee}code{padding:.1rem}pre code{border:none}pre{padding:1rem;overflow-x:auto}img{max-width:100%}hr{background:#000;height:1px;border:0}header{flex-basis:10rem;flex-grow:1;position:relative}header a{text-decoration:none}header li{margin-bottom:.2rem;text-align:right;margin-right:2rem}header a.active{font-weight:bold}header,section{padding:1rem}blockquote{font-style:italic;border-left:5px solid #ececec;padding-left:1rem}h1,h2,h3,h4,h5{line-height:1;margin:1rem 0;font-weight:600}section h1:first-child{margin-top:0}strong,b{font-weight:bold}.photos ul{list-style:none}.photos li{margin-bottom:1.5rem}.photo picture,.project picture{margin-bottom:0.5rem}.posts ul,header ul{list-style:none}.posts li{align-items:center;display:flex;justify-content:space-between;margin-bottom:.5rem}.posts li a,.posts li div,.projects li a{white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.posts li time,.projects li time{padding-left:1rem;white-space:nowrap;font-variant-numeric:tabular-nums}main{display:flex;flex-wrap:wrap;max-width:60rem;margin:2rem auto;padding:1rem}@media screen and (max-width: 45rem){header li{display:inline;margin-right:1rem}.logo{padding-bottom:1rem}header ul{border-bottom:1px solid #edf2f7;padding-bottom:2rem}nav ul{border-right:0px}.photos ul{margin-top:0.5rem}}section{flex-basis:0;flex-grow:999;min-width:70%;display:flex;flex-direction:column}figcaption{font-size:smaller}#share-bar{font-size:20px}#share-bar h4{margin-bottom:10px;font-weight:500}.share-button{margin:0px;margin-bottom:10px;margin-right:3px;border:1px solid #D3D6D2;padding:5px 10px 5px 10px}.share-button:hover{opacity:1;color:#ffffff}.fa-facebook-official{color:#3b5998}.fa-facebook-official:hover{background-color:#3b5998}.fa-twitter{color:#55acee}.fa-twitter:hover{background-color:#55acee}.fa-google-plus{color:#dd4b39}.fa-google-plus:hover{background-color:#dd4b39}.fa-pinterest-p{color:#cb2027}.fa-pinterest-p:hover{background-color:#cb2027}.fa-tumblr{color:#32506d}.fa-tumblr:hover{background-color:#32506d}.fa-reddit-alien{color:#ff4500}.fa-reddit-alien:hover{background-color:#ff4500}.fa-linkedin{color:#007bb5}.fa-linkedin:hover{background-color:#007bb5}.fa-envelope{color:#444444}.fa-envelope:hover{background-color:#444444}</style></head><body><main role="main"><header role="banner"><h1 class="logo">The Data Guy</h1><div class="page-author h-card p-author"><img src="/assets/circle-cropped.png" class="author-avatar u-photo" alt="Bhuvanesh"></div><nav role="navigation"><ul><li><a href="/" >Home</a></li><li><a href="/posts/" >Posts</a></li><li><a href="/categories/" >Categories</a></li><li><a href="/tags/" >Tags</a></li><li><a href="https://medium.com/@bhuvithedataguy" >Medium Blog</a></li><li><a href="/search" >Search Here</a></li></ul></nav></header><section class="post"><h2>Automate RedShift Vacuum And Analyze with Script</h2><p>Vacuum and Analyze process in AWS Redshift is a pain point to everyone, most of us trying to automate with their favorite scripting languge. AWS RedShift is an enterprise data warehouse solution to handle petabyte-scale data for you. AWS also improving its quality by adding a lot more features like Concurrency scaling, Spectrum, Auto WLM, etc. But for a DBA or a RedShift admin its always a headache to vacuum the cluster and do analyze to update the statistics. Since its build on top of the PostgreSQL database. But RedShift will do the Full vacuum without locking the tables. And they can trigger the auto vacuum at any time whenever the cluster load is less. But for a busy Cluster where everyday 200GB+ data will be added and modified some decent amount of data will not get benefit from the native auto vacuum feature. You know your workload, so you have to set a scheduled vacuum for your cluster and even we had such a situation where we need to build some more handy utility for my workload.</p><h2 id="vacuum-analyze-utility">Vacuum Analyze Utility:</h2><p>We all know that AWS has an awesome repository for community contributed utilities. We can see a utility for Vacuum as well. But due to some errors and python related dependencies (also this one module is referring modules from other utilities as well). So we wanted to have a utility with the flexibility that we are looking for. And that’s why you are here. We developed(replicated) a shell-based vacuum analyze utility which almost converted all the features from the existing utility also some additional features like DRY RUN and etc. Lets see how it works.</p><p>You can get the script from my <a href="https://github.com/BhuviTheDataGuy/RedShift-ToolKit/tree/master/VacuumAnalyzeUtility">github repo</a>.</p><h2 id="script-arguments">Script Arguments:</h2><p>To trigger the vacuum you need to provide three mandatory things.</p><ol><li>RedShift Endpoint</li><li>User Name</li><li>Database Name</li></ol><p>This utility will not support cross database vacuum, it’s the PostgreSQL limitation. There are some other parameters that will get generated automatically if you didn’t pass them as an argument. Please refer to the below table.</p><table><thead><tr><th>Argument</th><th>Details</th><th>Default</th></tr></thead><tbody><tr><td>-h</td><td>RedShift Endpoint</td><td> </td></tr><tr><td>-u</td><td>User name (super admin user)</td><td> </td></tr><tr><td>-P</td><td>password for the redshift user</td><td>use pgpass file</td></tr><tr><td>-p</td><td>RedShift Port</td><td>5439</td></tr><tr><td>-d</td><td>Database name</td><td> </td></tr><tr><td>-s</td><td>Schema name to vacuum/analyze, for multiple schemas then use comma (eg: ‘schema1,schema2’)</td><td>ALL</td></tr><tr><td>-t</td><td>Table name to vacuum/analyze, for multiple tables then use comma (eg: ‘table1,table2’)</td><td>ALL</td></tr><tr><td>-b</td><td>Blacklisted tables, these tables will be ignored from the vacuum/analyze</td><td>Nothing</td></tr><tr><td>-k</td><td>Blacklisted schemas, these schemas will be ignored from the vacuum/analyze</td><td>Nothing</td></tr><tr><td>-w</td><td>WLM slot count to allocate limited memory</td><td>1</td></tr><tr><td>-q</td><td>querygroup for the vacuum/analyze, Default=default (for now I didn’t use this in script)</td><td>default</td></tr><tr><td>-a</td><td>Perform analyze or not [Binary value, if 1 then Perform 0 means don’t Perform]</td><td>1</td></tr><tr><td>-r</td><td>set analyze_threshold_percent</td><td>5</td></tr><tr><td>-v</td><td>Perform vacuum or not [Binary value, if 1 then Perform 0 means don’t Perform]</td><td>1</td></tr><tr><td>-o</td><td>vacuum options [FULL, SORT ONLY, DELETE ONLY, REINDEX ]</td><td>SORT ONLY</td></tr><tr><td>-c</td><td>vacuum threshold percentage</td><td>80</td></tr><tr><td>-x</td><td>Filter the tables based on unsorted rows from svv_table_info</td><td>10</td></tr><tr><td>-f</td><td>Filter the tables based on stats_off from svv_table_info</td><td>10</td></tr><tr><td>-z</td><td>DRY RUN - just print the vacuum and analyze queries on the screen [1 Yes, 0 No]</td><td>0</td></tr></tbody></table><h2 id="installation">Installation:</h2><p>For this, you just need <code class="language-html highlighter-rouge">psql client</code> only, no need to install any other tools/software.</p><h2 id="example-commands">Example Commands:</h2><p>Run vacuum and Analyze on all the tables.</p><figure class="highlight"><pre><code class="language-sh" data-lang="sh">./vacuum-analyze-utility.sh <span class="nt">-h</span> endpoint <span class="nt">-u</span> bhuvi <span class="nt">-d</span> dev </code></pre></figure><p>Run vacuum and Analyze on the schema sc1, sc2.</p><figure class="highlight"><pre><code class="language-sh" data-lang="sh">./vacuum-analyze-utility.sh <span class="nt">-h</span> endpoint <span class="nt">-u</span> bhuvi <span class="nt">-d</span> dev <span class="nt">-s</span> <span class="s1">'sc1,sc2'</span></code></pre></figure><p>Run vacuum FULL on all the tables in all the schema except the schema sc1. But don’t want Analyze</p><figure class="highlight"><pre><code class="language-sh" data-lang="sh">./vacuum-analyze-utility.sh <span class="nt">-h</span> endpoint <span class="nt">-u</span> bhuvi <span class="nt">-d</span> dev <span class="nt">-k</span> sc1 <span class="nt">-o</span> FULL <span class="nt">-a</span> 0 <span class="nt">-v</span> 1
or
./vacuum-analyze-utility.sh <span class="nt">-h</span> endpoint <span class="nt">-u</span> bhuvi <span class="nt">-d</span> dev <span class="nt">-k</span> sc1 <span class="nt">-o</span> FULL <span class="nt">-a</span> 0</code></pre></figure><p>Run Analyze only on all the tables except the tables tb1,tbl3.</p><figure class="highlight"><pre><code class="language-sh" data-lang="sh">./vacuum-analyze-utility.sh <span class="nt">-h</span> endpoint <span class="nt">-u</span> bhuvi <span class="nt">-d</span> dev <span class="nt">-b</span> <span class="s1">'tbl1,tbl3'</span> <span class="nt">-a</span> 1 <span class="nt">-v</span> 0
or 
./vacuum-analyze-utility.sh <span class="nt">-h</span> endpoint <span class="nt">-u</span> bhuvi <span class="nt">-d</span> dev <span class="nt">-b</span> <span class="s1">'tbl1,tbl3'</span> <span class="nt">-v</span> 0</code></pre></figure><p>Use a password on the command line.</p><figure class="highlight"><pre><code class="language-sh" data-lang="sh">./vacuum-analyze-utility.sh <span class="nt">-h</span> endpoint <span class="nt">-u</span> bhuvi <span class="nt">-d</span> dev <span class="nt">-P</span> bhuvipassword</code></pre></figure><p>Run vacuum and analyze on the tables where unsorted rows are greater than 10%.</p><figure class="highlight"><pre><code class="language-sh" data-lang="sh">./vacuum-analyze-utility.sh <span class="nt">-h</span> endpoint <span class="nt">-u</span> bhuvi <span class="nt">-d</span> dev <span class="nt">-v</span> 1 <span class="nt">-a</span> 1 <span class="nt">-x</span> 10
or
./vacuum-analyze-utility.sh <span class="nt">-h</span> endpoint <span class="nt">-u</span> bhuvi <span class="nt">-d</span> dev <span class="nt">-x</span> 10</code></pre></figure><p>Run the Analyze on all the tables in schema sc1 where stats_off is greater than 5.</p><figure class="highlight"><pre><code class="language-sh" data-lang="sh">./vacuum-analyze-utility.sh <span class="nt">-h</span> endpoint <span class="nt">-u</span> bhuvi <span class="nt">-d</span> dev <span class="nt">-v</span> 0 <span class="nt">-a</span> 1 <span class="nt">-f</span> 5</code></pre></figure><p>Run the vacuum only on the table tbl1 which is in the schema sc1 with the Vacuum threshold 90%.</p><figure class="highlight"><pre><code class="language-sh" data-lang="sh">./vacuum-analyze-utility.sh <span class="nt">-h</span> endpoint <span class="nt">-u</span> bhuvi <span class="nt">-d</span> dev <span class="nt">-s</span> sc1 <span class="nt">-t</span> tbl1 <span class="nt">-a</span> 0 <span class="nt">-c</span> 90</code></pre></figure><p>Run analyze only the schema sc1 but set the <a href="https://docs.aws.amazon.com/redshift/latest/dg/r_analyze_threshold_percent.html">analyze_threshold_percent=0.01</a></p><figure class="highlight"><pre><code class="language-sh" data-lang="sh">./vacuum-analyze-utility.sh <span class="nt">-h</span> endpoint <span class="nt">-u</span> bhuvi <span class="nt">-d</span> dev <span class="nt">-s</span> sc1 <span class="nt">-t</span> tbl1 <span class="nt">-a</span> 1 <span class="nt">-v</span> 0 <span class="nt">-r</span> 0.01</code></pre></figure><p>Do a dry run (generate SQL queries) for analyze all the tables on the schema sc2.</p><figure class="highlight"><pre><code class="language-sh" data-lang="sh">./vacuum-analyze-utility.sh <span class="nt">-h</span> endpoint <span class="nt">-u</span> bhuvi <span class="nt">-d</span> dev <span class="nt">-s</span> sc2 <span class="nt">-z</span> 1</code></pre></figure><p>Do a dry run (generate SQL queries) for both vacuum and analyze for the table tbl3 on all the schema.</p><figure class="highlight"><pre><code class="language-sh" data-lang="sh">./vacuum-analyze-utility.sh <span class="nt">-h</span> endpoint <span class="nt">-u</span> bhuvi <span class="nt">-d</span> dev <span class="nt">-t</span> tbl3 <span class="nt">-z</span> 1</code></pre></figure><h2 id="schedule-different-vacuum-options-based-on-the-day">Schedule different vacuum options based on the day</h2><p>We’ll not full the Vacuum full on daily basis, so If you want to run vacumm only on Sunday and do vacuum <code class="language-html highlighter-rouge">SORT ONLY</code> on the other day’s without creating a new cron job you can handle this from the script.</p><p>Just remove this piece of the code.</p><figure class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="k">if</span> <span class="o">[[</span> <span class="nv">$vacuumoption</span> <span class="o">==</span> <span class="s1">'unset'</span> <span class="o">]]</span>
	<span class="k">then </span><span class="nv">vacuumoption</span><span class="o">=</span><span class="s1">'SORT ONLY'</span>
<span class="k">else
	</span><span class="nv">vacuumoption</span><span class="o">=</span><span class="nv">$vacuumoption</span>
<span class="k">fi</span></code></pre></figure><p>And add this lines.</p><figure class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="c">## Eg: run vacuum FULL on Sunday and SORT ONLY on other days</span>
<span class="k">if</span> <span class="o">[[</span> <span class="sb">`</span><span class="nb">date</span> <span class="s1">'+%a'</span><span class="sb">`</span> <span class="o">==</span> <span class="s1">'Sun'</span> <span class="o">]]</span>
	<span class="k">then  </span><span class="nv">vacuumoption</span><span class="o">=</span><span class="s1">'FULL'</span>
<span class="k">else 
	</span><span class="nv">vacuumoption</span><span class="o">=</span><span class="s2">"SORT ONLY"</span>
<span class="k">fi</span></code></pre></figure><h2 id="sample-output">Sample output:</h2><p><strong>For vacumm and Analyze:</strong></p><figure class="highlight"><pre><code class="language-sh" data-lang="sh">./vacuum-analyze-utility.sh <span class="nt">-h</span> endpoint <span class="nt">-u</span> bhuvi <span class="nt">-d</span> dev <span class="nt">-b</span> tbl1 <span class="nt">-k</span> sc1 <span class="nt">-a</span> 1  <span class="nt">-v</span> 1 <span class="nt">-x</span> 0 <span class="nt">-f</span> 0    
2020-04-13 18:35:25 Starting the process.....
2020-04-13 18:35:25 Validating the Host,User,Database arguments
2020-04-13 18:35:25 Perfect all the mandatory arguments are <span class="nb">set
</span>2020-04-13 18:35:25 Validating the Vacuum and Analyze arguments
2020-04-13 18:35:25 Vacuum Arguemnt is 1
2020-04-13 18:35:25 Analyze Arguemnt is 1
2020-04-13 18:35:25 Password will be taken from pgpass
2020-04-13 18:35:25 Getting the list of schema
2020-04-13 18:35:26 Getting the list of Tables
2020-04-13 18:35:26 Setting the other arguments
2020-04-13 18:35:27 Vacuum is Starting now, stay tune <span class="o">!!!</span>
2020-04-13 18:35:28 Vacuum <span class="k">done
</span>2020-04-13 18:35:29 Analyze is Starting now, Please wait...
2020-04-13 18:35:29 Analyze <span class="k">done</span></code></pre></figure><p><strong>For Dry Run:</strong></p><figure class="highlight"><pre><code class="language-sh" data-lang="sh">./vacuum-analyze-utility.sh <span class="nt">-h</span> endpoint <span class="nt">-u</span> bhuvi <span class="nt">-d</span> dev <span class="nt">-s</span> sc3 <span class="nt">-a</span> 1  <span class="nt">-v</span> 1 <span class="nt">-x</span> 80 <span class="nt">-f</span> 0 <span class="nt">-z</span> 1
2020-04-13 18:33:53 Starting the process.....
2020-04-13 18:33:53 Validating the Host,User,Database arguments
2020-04-13 18:33:53 Perfect all the mandatory arguments are <span class="nb">set
</span>2020-04-13 18:33:53 Validating the Vacuum and Analyze arguments
2020-04-13 18:33:53 Vacuum Arguemnt is 1
2020-04-13 18:33:53 Analyze Arguemnt is 1
2020-04-13 18:33:53 Password will be taken from pgpass
2020-04-13 18:33:53 Getting the list of schema
2020-04-13 18:33:54 Getting the list of Tables
2020-04-13 18:33:54 Setting the other arguments

DRY RUN <span class="k">for </span>vacuum
<span class="nt">------------------</span>
vacuum SORT ONLY public.nyc_data to 80 percent<span class="p">;</span>
vacuum SORT ONLY sc3.tbl3 to 80 percent<span class="p">;</span>

DRY RUN <span class="k">for </span>Analyze
<span class="nt">-------------------</span>
analyze public.nyc_data<span class="p">;</span>
analyze sc3.tbl3<span class="p">;</span></code></pre></figure><h2 id="conclusion">Conclusion:</h2><p>If you found any issues or looking for a feature please feel free to open an issue on the github page, also if you want to contribute for this utility please comment below.</p><h2 id="click-here-to-get-the-code-"><a href="https://github.com/BhuviTheDataGuy/RedShift-ToolKit/tree/master/VacuumAnalyzeUtility">Click here to get the Code </a></h2><span class="meta"><time datetime="2020-04-14T01:15:00+00:00">April 14, 2020</time> &middot; <a href="/tags/#aws">aws</a>, <a href="/tags/#redshift">redshift</a>, <a href="/tags/#shellscript">shellscript</a>, <a href="/tags/#automation">automation</a></span><hr> <!--<span class="meta"><time datetime="2020-04-14T01:15:00+00:00">April 14, 2020</time> &middot; <a class="post" href="/tag/aws">aws</a>, <a class="post" href="/tag/redshift">redshift</a>, <a class="post" href="/tag/shellscript">shellscript</a>, <a class="post" href="/tag/automation">automation</a></span> --></section></main></body></html>
