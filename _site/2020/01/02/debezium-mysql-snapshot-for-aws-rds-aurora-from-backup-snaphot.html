<!DOCTYPE html><html lang="en" ><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><link href="/assets/css/syntax.css" rel="stylesheet"><title>Debezium MySQL Snapshot For AWS RDS Aurora From Backup Snaphot | The Data Guy</title><meta name="generator" content="Jekyll v4.0.0" /><meta property="og:title" content="Debezium MySQL Snapshot For AWS RDS Aurora From Backup Snaphot" /><meta name="author" content="Bhuvanesh" /><meta property="og:locale" content="en_US" /><meta name="description" content="Debezium MySQL connector load historical data of AWS RDS Aurora from its snapshot. Using crash recovery, we can get the binlog information." /><meta property="og:description" content="Debezium MySQL connector load historical data of AWS RDS Aurora from its snapshot. Using crash recovery, we can get the binlog information." /><meta property="og:site_name" content="The Data Guy" /><meta property="og:image" content="/assets/Debezium%20MySQL%20Snapshot%20For%20AWS%20RDS%20Aurora%20From%20Backup%20Snaphot.jpg" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-01-02T08:43:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:image" content="/assets/Debezium%20MySQL%20Snapshot%20For%20AWS%20RDS%20Aurora%20From%20Backup%20Snaphot.jpg" /><meta property="twitter:title" content="Debezium MySQL Snapshot For AWS RDS Aurora From Backup Snaphot" /><meta name="twitter:site" content="@bhuvithedataguy" /><meta name="twitter:creator" content="@https://twitter.com/BhuviTheDataGuy" /> <script type="application/ld+json"> {"dateModified":"2020-01-02T08:43:00+00:00","datePublished":"2020-01-02T08:43:00+00:00","image":"/assets/Debezium%20MySQL%20Snapshot%20For%20AWS%20RDS%20Aurora%20From%20Backup%20Snaphot.jpg","url":"/2020/01/02/debezium-mysql-snapshot-for-aws-rds-aurora-from-backup-snaphot","mainEntityOfPage":{"@type":"WebPage","@id":"/2020/01/02/debezium-mysql-snapshot-for-aws-rds-aurora-from-backup-snaphot"},"@type":"BlogPosting","author":{"@type":"Person","name":"Bhuvanesh"},"description":"Debezium MySQL connector load historical data of AWS RDS Aurora from its snapshot. Using crash recovery, we can get the binlog information.","headline":"Debezium MySQL Snapshot For AWS RDS Aurora From Backup Snaphot","@context":"https://schema.org"}</script><style> *,:after,:before{box-sizing:border-box;background-color:inherit;color:inherit;margin:0;padding:0}body{font-family:system-ui, sans-serif;-webkit-font-smoothing:antialiased;text-rendering:optimizeLegibility;line-height:1.7;font-size:1rem;color:#16171a}nav ul{border-right:1px solid #edf2f7}a{color:#000;text-decoration-skip-ink:auto;text-decoration:underline}pre{margin:.5rem 0;padding:.5rem}.post p{margin:.5rem 0}.post h1,.post h2,.post h3,.post h4{margin:1rem 0}.post h2:first-child,.project h2:first-child,.photo h2:first-child{margin-top:0}.meta{margin:2rem 0}code,pre{background:#ecedee}code{padding:.1rem}pre code{border:none}pre{padding:1rem;overflow-x:auto}img{max-width:100%}hr{background:#000;height:1px;border:0}header{flex-basis:10rem;flex-grow:1;position:relative}header a{text-decoration:none}header li{margin-bottom:.2rem;text-align:right;margin-right:2rem}header a.active{font-weight:bold}header,section{padding:1rem}blockquote{font-style:italic;border-left:5px solid #ececec;padding-left:1rem}h1,h2,h3,h4,h5{line-height:1;margin:1rem 0;font-weight:600}section h1:first-child{margin-top:0}strong,b{font-weight:bold}.photos ul{list-style:none}.photos li{margin-bottom:1.5rem}.photo picture,.project picture{margin-bottom:0.5rem}.posts ul,header ul{list-style:none}.posts li{align-items:center;display:flex;justify-content:space-between;margin-bottom:.5rem}.posts li a,.posts li div,.projects li a{white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.posts li time,.projects li time{padding-left:1rem;white-space:nowrap;font-variant-numeric:tabular-nums}main{display:flex;flex-wrap:wrap;max-width:60rem;margin:2rem auto;padding:1rem}@media screen and (max-width: 45rem){header li{display:inline;margin-right:1rem}.logo{padding-bottom:1rem}header ul{border-bottom:1px solid #edf2f7;padding-bottom:2rem}nav ul{border-right:0px}.photos ul{margin-top:0.5rem}}section{flex-basis:0;flex-grow:999;min-width:70%;display:flex;flex-direction:column}figcaption{font-size:smaller}#share-bar{font-size:20px}#share-bar h4{margin-bottom:10px;font-weight:500}.share-button{margin:0px;margin-bottom:10px;margin-right:3px;border:1px solid #D3D6D2;padding:5px 10px 5px 10px}.share-button:hover{opacity:1;color:#ffffff}.fa-facebook-official{color:#3b5998}.fa-facebook-official:hover{background-color:#3b5998}.fa-twitter{color:#55acee}.fa-twitter:hover{background-color:#55acee}.fa-google-plus{color:#dd4b39}.fa-google-plus:hover{background-color:#dd4b39}.fa-pinterest-p{color:#cb2027}.fa-pinterest-p:hover{background-color:#cb2027}.fa-tumblr{color:#32506d}.fa-tumblr:hover{background-color:#32506d}.fa-reddit-alien{color:#ff4500}.fa-reddit-alien:hover{background-color:#ff4500}.fa-linkedin{color:#007bb5}.fa-linkedin:hover{background-color:#007bb5}.fa-envelope{color:#444444}.fa-envelope:hover{background-color:#444444}</style></head><body><main role="main"><header role="banner"><h1 class="logo">The Data Guy</h1><div class="page-author h-card p-author"><img src="/assets/circle-cropped.png" class="author-avatar u-photo" alt="Bhuvanesh"></div><nav role="navigation"><ul><li><a href="/" >Home</a></li><li><a href="/posts/" >Posts</a></li><li><a href="/categories/" >Categories</a></li><li><a href="/tags/" >Tags</a></li><li><a href="https://medium.com/@bhuvithedataguy" >Medium Blog</a></li><li><a href="/search" >Search Here</a></li></ul></nav></header><section class="post"><h2>Debezium MySQL Snapshot For AWS RDS Aurora From Backup Snaphot</h2><p>I have published enough Debezium MySQL connector tutorials for taking snapshots from Read Replica. To continue my research I wanted to do something for AWS RDS Aurora as well. But aurora is not using binlog bases replication. So we can’t use the list of tutorials that I published already. In Aurora, we can get the binlog file name and its position from its snapshot of the source Cluster. So I used a snapshot for loading the historical data, and once it’s loaded we can resume the CDC from the main cluster.</p><h2 id="requirements">Requirements:</h2><ol><li>Running aurora cluster.</li><li>Aurora cluster must have <a href="https://aws.amazon.com/premiumsupport/knowledge-center/enable-binary-logging-aurora/">binlogs enabled</a>.</li><li>Make binlog retention period to a minimum 3 days(its a best practice).</li><li>Debezium connector should be able to access both the clusters.</li><li>Make sure you have different security groups for the main RDS Aurora cluster and the Snapshot cluster.</li></ol><h2 id="sample-data-in-source-aurora">Sample data in source aurora:</h2><figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="k">create</span> <span class="k">database</span> <span class="n">bhuvi</span><span class="p">;</span>
<span class="n">use</span> <span class="n">bhuvi</span><span class="p">;</span>

<span class="k">create</span> <span class="k">table</span> <span class="n">rohi</span> <span class="p">(</span>
<span class="n">id</span> <span class="nb">int</span><span class="p">,</span>
<span class="n">fn</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
<span class="n">ln</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
<span class="n">phone</span> <span class="nb">int</span><span class="p">);</span>

<span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span></code></pre></figure><h2 id="take-aurora-snapshot">Take Aurora snapshot:</h2><p>Go to the RDS console and select your source Aurora master node. Take a snapshot of it. Once the snapshot has been done, you see that in the snapshots tab.</p><p><img src="/assets/Debezium MySQL Snapshot For AWS RDS Aurora From Backup Snaphot1.jpg" alt="" /></p><h2 id="new-cluster-from-snapshot">New cluster from snapshot:</h2><p>Then create a new cluster from the snapshot. Once its launched, we can get the binlog info from the logs.</p><p>In RDS Console, select the instance name. Click on the Logs &amp; Events tab. Below the Recent events, you can see the binlog information of the source Aurora node while talking the snapshot. This cluster also needs to enable with binlog.</p><p><img src="/assets/Debezium MySQL Snapshot For AWS RDS Aurora From Backup Snaphot2.jpg" alt="" /></p><h2 id="register-the-mysql-connector">Register the MySQL Connector:</h2><p>Follow this link to <a href="https://thedataguy.in/build-production-grade-debezium-with-confluent-kafka-cluster/">configure Kafka cluster and connector.</a> Create a file called <code class="language-html highlighter-rouge">mysql.json</code> and add the Snapshot cluster’s information.</p><figure class="highlight"><pre><code class="language-json" data-lang="json"><span class="p">{</span><span class="w">
</span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-connector-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"config"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-connector-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"connector.class"</span><span class="p">:</span><span class="w"> </span><span class="s2">"io.debezium.connector.mysql.MySqlConnector"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.server.id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1"</span><span class="p">,</span><span class="w">
</span><span class="nl">"tasks.max"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.history.kafka.bootstrap.servers"</span><span class="p">:</span><span class="w"> </span><span class="s2">"YOUR-BOOTSTRAP-SERVER:9092"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.history.kafka.topic"</span><span class="p">:</span><span class="w"> </span><span class="s2">"schema-changes.mysql"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.server.name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.hostname"</span><span class="p">:</span><span class="w"> </span><span class="s2">"SNAPSHOT-INSTANCE-ENDPOINT"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.port"</span><span class="p">:</span><span class="w"> </span><span class="s2">"3306"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.user"</span><span class="p">:</span><span class="w"> </span><span class="s2">"bhuvi"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.password"</span><span class="p">:</span><span class="w"> </span><span class="s2">"****"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.whitelist"</span><span class="p">:</span><span class="w"> </span><span class="s2">"bhuvi"</span><span class="p">,</span><span class="w">
</span><span class="nl">"snapshot.mode"</span><span class="p">:</span><span class="w"> </span><span class="s2">"initial"</span><span class="p">,</span><span class="w">
</span><span class="nl">"snapshot.locking.mode"</span><span class="p">:</span><span class="w"> </span><span class="s2">"none"</span><span class="p">,</span><span class="w">
</span><span class="nl">"key.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"value.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"key.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"value.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.key.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.value.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.key.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.value.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms"</span><span class="p">:</span><span class="w"> </span><span class="s2">"unwrap"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms.unwrap.add.source.fields"</span><span class="p">:</span><span class="w"> </span><span class="s2">"ts_ms"</span><span class="p">,</span><span class="w">
</span><span class="nl">"tombstones.on.delete"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms.unwrap.type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"io.debezium.transforms.ExtractNewRecordState"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="p">}</span></code></pre></figure><p>Run the below command to register it on the connector node.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">curl <span class="nt">-X</span> POST <span class="nt">-H</span> <span class="s2">"Accept: application/json"</span> <span class="nt">-H</span> <span class="s2">"Content-Type: application/json"</span> http://localhost:8083/connectors <span class="nt">-d</span> @mysql.json</code></pre></figure><p>Once the snapshot has been done, you can see the snapshot cluster’s current binlog file name and its position in the <code class="language-html highlighter-rouge">connect-offsets</code> topic.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafka-console-consumer <span class="nt">--bootstrap-server</span> localhost:9092 <span class="nt">--topic</span> connect-offsets <span class="nt">--from-beginning</span>

<span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"mysql-bin-changelog.000006"</span>,<span class="s2">"pos"</span>:154<span class="o">}</span></code></pre></figure><h2 id="add-more-data-on-the-source-cluster">Add more data on the source Cluster:</h2><p>To simulate the real production setup, add few more rows to the <code class="language-html highlighter-rouge">rohi</code> table.</p><figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span></code></pre></figure><p>Also, create a new table.</p><figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="n">use</span> <span class="n">bhuvi</span><span class="p">;</span>
<span class="k">create</span> <span class="k">table</span> <span class="n">testtbl</span> <span class="p">(</span><span class="n">id</span> <span class="nb">int</span><span class="p">);</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">testtbl</span> <span class="k">values</span> <span class="p">(</span><span class="mi">1</span><span class="p">);</span></code></pre></figure><p>Because, once we switch to the source cluster, it should read these new data.</p><h2 id="update-the-source-aurora-binlog-info">Update the Source Aurora binlog info:</h2><p>Stop the connector service and manually inject the binlog information that we got from the Snapshot cluster’s Log &amp; Events section.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">connector-node# systemctl stop confluent-connect-distributed</code></pre></figure><p>Get the last read binlog information and its parition from the <code class="language-html highlighter-rouge">connect-offsets</code> topic.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafkacat <span class="nt">-b</span> localhost:9092 <span class="nt">-C</span> <span class="nt">-t</span> connect-offsets  <span class="nt">-f</span> <span class="s1">'Partition(%p) %k %s\n'</span>

Partition<span class="o">(</span>0<span class="o">)</span> <span class="o">[</span><span class="s2">"mysql-connector-db01"</span>,<span class="o">{</span><span class="s2">"server"</span>:<span class="s2">"mysql-db01"</span><span class="o">}]</span> <span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"mysql-bin-changelog.000006"</span>,<span class="s2">"pos"</span>:154<span class="o">}</span></code></pre></figure><ul><li><code class="language-html highlighter-rouge">kafkacat</code> - command-line utility from confluent.</li><li><code class="language-html highlighter-rouge">-b localhost:9092</code> - broker details</li><li><code class="language-html highlighter-rouge">-C</code> - Consumer</li><li><code class="language-html highlighter-rouge">-t connect-offsets</code> - topic</li><li><code class="language-html highlighter-rouge">Partition(0)</code> - The partition name where we have the binlog info.</li><li><code class="language-html highlighter-rouge">mysql-connector-db01</code> - connector name</li><li><code class="language-html highlighter-rouge">"server":"mysql-db01</code> - server name we used in <code class="language-html highlighter-rouge">mysql.json</code> file</li></ul><p>Run the following command to inject the binlog info to the <code class="language-html highlighter-rouge">connect-offsets</code> topic.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nb">echo</span> <span class="s1">'["mysql-connector-db01",{"server":"mysql-db01"}]|{"file":"mysql-bin-changelog.000002","pos":2170}'</span> | <span class="se">\</span>
kafkacat <span class="nt">-P</span> <span class="nt">-b</span> localhost:9092 <span class="nt">-t</span> connect-offsets <span class="nt">-K</span><span class="se">\ </span>| <span class="nt">-p</span> 0</code></pre></figure><ul><li><code class="language-html highlighter-rouge">mysql-connector-db01</code> - connector name</li><li><code class="language-html highlighter-rouge">"server":"mysql-db01</code> - server name we used in <code class="language-html highlighter-rouge">mysql.json</code> file</li><li><code class="language-html highlighter-rouge">{"file":"mysql-bin-changelog.000002","pos":2170}</code> - Binlog info from the snapshot cluster’s log.</li><li><code class="language-html highlighter-rouge">kafkacat</code> - command-line utility from confluent.</li><li><code class="language-html highlighter-rouge">-P</code> - Producer</li><li><code class="language-html highlighter-rouge">-b localhost:9092</code> - broker details</li><li><code class="language-html highlighter-rouge">-t connect-offsets</code> - topic</li><li><code class="language-html highlighter-rouge">-p 0</code> Partition where we have the binlog info.</li></ul><p>Now if you read the data from the consumer, it’ll show the new binlog.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafka-console-consumer <span class="nt">--bootstrap-server</span> localhost:9092 <span class="nt">--topic</span> connect-offsets <span class="nt">--from-beginning</span>

<span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"mysql-bin-changelog.000006"</span>,<span class="s2">"pos"</span>:154<span class="o">}</span>
<span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"mysql-bin-changelog.000002"</span>,<span class="s2">"pos"</span>:2170<span class="o">}</span></code></pre></figure><h2 id="switch-to-source-cluster">Switch to Source Cluster:</h2><p>Before doing the switchover, we need to make that the connector should not access to the snapshot cluster once the connector service started. We can achieve this in 2 ways.</p><ol><li>Anyhow, we read all the from the snapshot cluster, so delete it.</li><li>In the Snapshot cluster’s security group, remove the connector’s node IP.</li></ol><p>I recommend using the 2nd option. Now start the connector service. After a few seconds, you can see the logs like below.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="se">\[</span>2020-01-02 06:57:21,448<span class="se">\]</span> INFO Starting MySqlConnectorTask with configuration: <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,450<span class="se">\]</span> INFO    connector.class <span class="o">=</span> io.debezium.connector.mysql.MySqlConnector <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,450<span class="se">\]</span> INFO    snapshot.locking.mode <span class="o">=</span> none <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,451<span class="se">\]</span> INFO    tasks.max <span class="o">=</span> 1 <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,451<span class="se">\]</span> INFO    database.history.kafka.topic <span class="o">=</span> replica-schema-changes.mysql <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,452<span class="se">\]</span> INFO    transforms <span class="o">=</span> unwrap <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,452<span class="se">\]</span> INFO    internal.key.converter.schemas.enable <span class="o">=</span> <span class="nb">false</span> <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,452<span class="se">\]</span> INFO    transforms.unwrap.add.source.fields <span class="o">=</span> ts_ms <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    tombstones.on.delete <span class="o">=</span> <span class="nb">false</span> <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    transforms.unwrap.type <span class="o">=</span> io.debezium.transforms.ExtractNewRecordState <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    value.converter <span class="o">=</span> org.apache.kafka.connect.json.JsonConverter <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    database.whitelist <span class="o">=</span> bhuvi <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    key.converter <span class="o">=</span> org.apache.kafka.connect.json.JsonConverter <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    database.user <span class="o">=</span> admin <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    database.server.id <span class="o">=</span> 1 <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    database.history.kafka.bootstrap.servers <span class="o">=</span> 172.31.40.132:9092 <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    database.server.name <span class="o">=</span> mysql-db01 <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    database.port <span class="o">=</span> 3306 <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    key.converter.schemas.enable <span class="o">=</span> <span class="nb">false</span> <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    internal.key.converter <span class="o">=</span> org.apache.kafka.connect.json.JsonConverter <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    task.class <span class="o">=</span> io.debezium.connector.mysql.MySqlConnectorTask <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    database.hostname <span class="o">=</span> snapshot-cluster.cluster-chbcar19iy5o.us-east-1.rds.amazonaws.com <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    database.password <span class="o">=</span> <span class="k">********</span> <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    internal.value.converter.schemas.enable <span class="o">=</span> <span class="nb">false</span> <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    name <span class="o">=</span> mysql-connector-db01 <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    value.converter.schemas.enable <span class="o">=</span> <span class="nb">false</span> <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    internal.value.converter <span class="o">=</span> org.apache.kafka.connect.json.JsonConverter <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    snapshot.mode <span class="o">=</span> initial <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,512<span class="se">\]</span> INFO <span class="se">\[</span>Producer <span class="nv">clientId</span><span class="o">=</span>connector-producer-mysql-connector-db01-0<span class="se">\]</span> Cluster ID: H-jsdNk9SUuud35n3AIk8g <span class="o">(</span>org.apache.kafka.clients.Metadata<span class="o">)</span></code></pre></figure><h3 id="update-the-endpoint">Update the Endpoint:</h3><p>Create an updated config file which has the endpoint of Source Aurora endpoint and the <code class="language-html highlighter-rouge">snapshot mode = schema only recovery</code> .</p><p>And the main important thing is use a different topic for schema changes history. Else you’ll end up with some error like below.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">ERROR Failed due to error: Error processing binlog event <span class="o">(</span>io.debezium.connector.mysql.BinlogReader<span class="o">)</span>
org.apache.kafka.connect.errors.ConnectException: Encountered change event <span class="k">for </span>table bhuvi.rohi whose schema isn<span class="s1">'t known to this connector</span></code></pre></figure><p>File: mysql-update.json</p><figure class="highlight"><pre><code class="language-json" data-lang="json"><span class="p">{</span><span class="w">
</span><span class="nl">"connector.class"</span><span class="p">:</span><span class="w"> </span><span class="s2">"io.debezium.connector.mysql.MySqlConnector"</span><span class="p">,</span><span class="w">
</span><span class="nl">"snapshot.locking.mode"</span><span class="p">:</span><span class="w"> </span><span class="s2">"none"</span><span class="p">,</span><span class="w">
</span><span class="nl">"tasks.max"</span><span class="p">:</span><span class="w"> </span><span class="s2">"3"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.history.kafka.topic"</span><span class="p">:</span><span class="w"> </span><span class="s2">"schema-changes.mysql"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms"</span><span class="p">:</span><span class="w"> </span><span class="s2">"unwrap"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.key.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms.unwrap.add.source.fields"</span><span class="p">:</span><span class="w"> </span><span class="s2">"ts_ms"</span><span class="p">,</span><span class="w">
</span><span class="nl">"tombstones.on.delete"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms.unwrap.type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"io.debezium.transforms.ExtractNewRecordState"</span><span class="p">,</span><span class="w">
</span><span class="nl">"value.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.whitelist"</span><span class="p">:</span><span class="w"> </span><span class="s2">"bhuvi"</span><span class="p">,</span><span class="w">
</span><span class="nl">"key.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.user"</span><span class="p">:</span><span class="w"> </span><span class="s2">"admin"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.server.id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.history.kafka.bootstrap.servers"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BROKER-NODE-IP:9092"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.server.name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.port"</span><span class="p">:</span><span class="w"> </span><span class="s2">"3306"</span><span class="p">,</span><span class="w">
</span><span class="nl">"key.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.key.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.hostname"</span><span class="p">:</span><span class="w"> </span><span class="s2">"SOURCE-AURORA-ENDPOINT"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.password"</span><span class="p">:</span><span class="w"> </span><span class="s2">"*****"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.value.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-connector-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"value.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.value.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"snapshot.mode"</span><span class="p">:</span><span class="w"> </span><span class="s2">"SCHEMA_ONLY_RECOVERY"</span><span class="w">
</span><span class="p">}</span></code></pre></figure><p>Run the below command to update the MySQL connector.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">curl <span class="nt">-X</span> PUT <span class="nt">-H</span> <span class="s2">"Accept: application/json"</span> <span class="nt">-H</span> <span class="s2">"Content-Type: application/json"</span> http://localhost:8083/connectors/mysql-connector-db01/config <span class="nt">-d</span> @mysql-update.json</code></pre></figure><p>Then immediately it’ll start reading from the Source Aurora cluster from the binlog position <code class="language-html highlighter-rouge">mysql-bin-changelog.000002 2170</code></p><p>You can see these changes from the <code class="language-html highlighter-rouge">connect-offsets</code> topic.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafka-console-consumer <span class="nt">--bootstrap-server</span> localhost:9092 <span class="nt">--topic</span> connect-offsets <span class="nt">--from-beginning</span>

<span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"mysql-bin-changelog.000006"</span>,<span class="s2">"pos"</span>:154<span class="o">}</span>
<span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"mysql-bin-changelog.000002"</span>,<span class="s2">"pos"</span>:2170<span class="o">}</span>
<span class="o">{</span><span class="s2">"ts_sec"</span>:1577948351,<span class="s2">"file"</span>:<span class="s2">"mysql-bin-changelog.000003"</span>,<span class="s2">"pos"</span>:1207,<span class="s2">"row"</span>:1,<span class="s2">"server_id"</span>:2115919109,<span class="s2">"event"</span>:2<span class="o">}</span></code></pre></figure><p>And we add 2 more rows to the rohi table. You can see those new values from the <code class="language-html highlighter-rouge">bhuvi.rohi</code> topic.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafka-console-consumer <span class="nt">--bootstrap-server</span> localhost:9092 <span class="nt">--topic</span> mysql-db01.bhuvi.rohi <span class="nt">--from-beginning</span>
<span class="o">{</span><span class="s2">"id"</span>:1,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:0<span class="o">}</span>
<span class="o">{</span><span class="s2">"id"</span>:2,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:0<span class="o">}</span>
<span class="o">{</span><span class="s2">"id"</span>:3,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:0<span class="o">}</span>
<span class="o">{</span><span class="s2">"id"</span>:4,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:0<span class="o">}</span>
<span class="o">{</span><span class="s2">"id"</span>:5,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:0<span class="o">}</span>

<span class="o">{</span><span class="s2">"id"</span>:6,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:1577948298000<span class="o">}</span>
<span class="o">{</span><span class="s2">"id"</span>:7,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:1577948304000<span class="o">}</span></code></pre></figure><p>Also, you can the new table <code class="language-html highlighter-rouge">testtbl</code> added to the topic.</p><figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafka-topics <span class="nt">--zookeeper</span> localhost:2181 <span class="nt">--list</span>

connect-configs
connect-offsets
connect-status
default_ksql_processing_log
mysql-db01
mysql-db01.bhuvi.rohi
mysql-db01.bhuvi.testtbl
replica-schema-changes.mysql
schema-changes.mysql</code></pre></figure><h3 id="debezium-series-blogs">Debezium Series blogs:</h3><ol><li><a href="https://thedataguy.in/build-production-grade-debezium-with-confluent-kafka-cluster/">Build Production Grade Debezium Cluster With Confluent Kafka</a></li><li><a href="https://thedataguy.in/monitor-debezium-mysql-connector-with-prometheus-and-grafana/">Monitor Debezium MySQL Connector With Prometheus And Grafana</a></li><li><a href="https://thedataguy.in/debezium-mysql-snapshot-from-read-replica-with-gtid/">Debezium MySQL Snapshot From Read Replica With GTID</a></li><li><a href="https://thedataguy.in/debezium-mysql-snapshot-from-read-replica-and-resume-from-master/">Debezium MySQL Snapshot From Read Replica And Resume From Master</a></li><li><a href="https://thedataguy.in/debezium-mysql-snapshot-for-aws-rds-aurora-from-backup-snaphot/">Debezium MySQL Snapshot For AWS RDS Aurora From Backup Snaphot</a></li><li><a href="https://medium.com/searce/realtime-cdc-from-mysql-using-aws-msk-with-debezium-28da5a4ca873">RealTime CDC From MySQL Using AWS MSK With Debezium</a></li></ol><span class="meta"><time datetime="2020-01-02T08:43:00+00:00">January 2, 2020</time> &middot; <a href="/tags/#aws">aws</a>, <a href="/tags/#rds">rds</a>, <a href="/tags/#aurora">aurora</a>, <a href="/tags/#kafka">kafka</a>, <a href="/tags/#debezium">debezium</a></span><hr> <!--<span class="meta"><time datetime="2020-01-02T08:43:00+00:00">January 2, 2020</time> &middot; <a class="post" href="/tag/aws">aws</a>, <a class="post" href="/tag/rds">rds</a>, <a class="post" href="/tag/aurora">aurora</a>, <a class="post" href="/tag/kafka">kafka</a>, <a class="post" href="/tag/debezium">debezium</a></span> --></section></main></body></html>
