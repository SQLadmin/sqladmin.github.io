I"¶r<p>The snapshot in Debezium will do a historical data load from the source database to the Kafka topics. But generally its not a good practice to this if you have a huge data in your tables. Recently I have published many blog posts to perform this snapshot from Read Replica(with/without GTID, AWS Aurora). One guy commented that, in GCP the MySQL managed service is called CloudSQL. There we donâ€™t have much control to stop replication, perform the modifications that we want. So how can we avoid snapshots in CloudSQL and take debezium snapshots from CloudSQL Read Replica? I have spent some time today and figured out a way to do this.</p>

<h2 id="the-approach">The Approach:</h2>

<p>We canâ€™t enable binlogs on read replica. So we have to setup an external read replica for this. If the external replica is a VM, then we can enable the <code class="language-html highlighter-rouge">log-slave-updates</code> with GTID. Then we can <a href="https://thedataguy.in/debezium-mysql-snapshot-from-read-replica-with-gtid/"><strong>follow this blog post</strong></a> to solve this problem. But I want to solve this by using CloudSQL read replica.</p>

<ul>
  <li>For this create a new read replica for your cloudsql.</li>
  <li>If you already have a read replica, then create one more (because weâ€™ll break the replication, so donâ€™t use the active one).</li>
  <li>Disable the replication on the new Replica and make a note of the masterâ€™s binlog information.</li>
  <li>Then Promote the replica. So itâ€™ll automatically enable the binlog.</li>
  <li>Now create a connector to read data from the replica node.</li>
  <li>Once the snapshot is done, manually update the <code class="language-html highlighter-rouge">connect-offset</code> with Masterâ€™s binlog info.</li>
  <li>Update the connector with Masterâ€™s IP address.</li>
  <li>Then itâ€™ll read from Master.</li>
</ul>

<h2 id="proof-of-concept">Proof Of Concept:</h2>

<p>Read my previous blog posts to install and configure Confluent Kafka connect and etc.</p>

<ul>
  <li>CloudSQL Master IP  - 172.24.0.13</li>
  <li>CloudSQL Replica IP - 172.24.0.19</li>
</ul>

<h2 id="sample-data">Sample data:</h2>

<p>Create a new database to test this sync and insert some values.</p>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="k">create</span> <span class="k">database</span> <span class="n">bhuvi</span><span class="p">;</span>
<span class="n">use</span> <span class="n">bhuvi</span><span class="p">;</span>
<span class="k">create</span> <span class="k">table</span> <span class="n">rohi</span> <span class="p">(</span>
<span class="n">id</span> <span class="nb">int</span><span class="p">,</span>
<span class="n">fn</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
<span class="n">ln</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
<span class="n">phone</span> <span class="nb">int</span><span class="p">);</span>

<span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span></code></pre></figure>

<p>Once your replica is in sync with Master, disable the replication from the CloudSQL Console.</p>

<p><img src="/assets/Debezium MySQL Snapshot For CloudSQL(MySQL) From Replica1.jpg" alt="" /></p>

<p>Then login to the Replica and get the masterâ€™s binlog file name and position from the <code class="language-html highlighter-rouge">show slave status</code></p>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="n">Master_Host</span><span class="p">:</span> <span class="mi">172</span><span class="p">.</span><span class="mi">24</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">13</span>
<span class="n">Master_User</span><span class="p">:</span> <span class="n">cloudsqlreplica</span>
<span class="n">Master_Port</span><span class="p">:</span> <span class="mi">3306</span>
<span class="n">Connect_Retry</span><span class="p">:</span> <span class="mi">60</span>
<span class="n">Master_Log_File</span><span class="p">:</span> <span class="n">mysql</span><span class="o">-</span><span class="n">bin</span><span class="p">.</span><span class="mi">000001</span>
<span class="n">Read_Master_Log_Pos</span><span class="p">:</span> <span class="mi">10259755</span>
<span class="n">Relay_Log_File</span><span class="p">:</span> <span class="n">relay</span><span class="o">-</span><span class="n">log</span><span class="p">.</span><span class="mi">000002</span>
<span class="n">Relay_Log_Pos</span><span class="p">:</span> <span class="mi">26567</span>
<span class="n">Relay_Master_Log_File</span><span class="p">:</span> <span class="n">mysql</span><span class="o">-</span><span class="n">bin</span><span class="p">.</span><span class="mi">000001</span>
<span class="n">Slave_IO_Running</span><span class="p">:</span> <span class="k">No</span>
<span class="n">Slave_SQL_Running</span><span class="p">:</span> <span class="k">No</span>
<span class="n">Last_Error</span><span class="p">:</span>
<span class="n">Skip_Counter</span><span class="p">:</span> <span class="mi">0</span>
<span class="n">Exec_Master_Log_Pos</span><span class="p">:</span> <span class="mi">10259755</span>  
<span class="n">Master_UUID</span><span class="p">:</span> <span class="n">c3c1d467</span><span class="o">-</span><span class="mi">3</span><span class="n">bee</span><span class="o">-</span><span class="mi">11</span><span class="n">ea</span><span class="o">-</span><span class="mi">907</span><span class="n">b</span><span class="o">-</span><span class="mi">4201</span><span class="n">ac18000c</span></code></pre></figure>

<ul>
  <li>Binlog File Name - Master_Log_File</li>
  <li>Binlog Position - 10259755</li>
  <li>Maserâ€™s UUID - Master_UUID</li>
</ul>

<p>Now promote the replica, itâ€™ll enable the binlog on this replica server.</p>

<p><img src="/assets/Debezium MySQL Snapshot For CloudSQL(MySQL) From Replica2.jpg" alt="" /></p>

<p>To simulate the complexity, add one more row on the master node(this row will not be replicated, since the replication is disables). So once the snapshot done, weâ€™ll switch the MySQL IP. Then it should read this new row.</p>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span></code></pre></figure>

<h2 id="create-the-mysql-connector">Create the MySQL Connector:</h2>

<p>Use the below MySQL connector JSON config.  (replace the MySQL details, kafka details, and Transformation things)</p>

<figure class="highlight"><pre><code class="language-json" data-lang="json"><span class="p">{</span><span class="w">
</span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-connector-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"config"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-connector-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"connector.class"</span><span class="p">:</span><span class="w"> </span><span class="s2">"io.debezium.connector.mysql.MySqlConnector"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.server.id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1"</span><span class="p">,</span><span class="w">
</span><span class="nl">"tasks.max"</span><span class="p">:</span><span class="w"> </span><span class="s2">"3"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.history.kafka.bootstrap.servers"</span><span class="p">:</span><span class="w"> </span><span class="s2">"10.128.0.12:9092"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.history.kafka.topic"</span><span class="p">:</span><span class="w"> </span><span class="s2">"replica-schema-changes.mysql"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.server.name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.hostname"</span><span class="p">:</span><span class="w"> </span><span class="s2">"172.24.0.19"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.port"</span><span class="p">:</span><span class="w"> </span><span class="s2">"3306"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.user"</span><span class="p">:</span><span class="w"> </span><span class="s2">"root"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.password"</span><span class="p">:</span><span class="w"> </span><span class="s2">"****"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.whitelist"</span><span class="p">:</span><span class="w"> </span><span class="s2">"bhuvi"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.key.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"key.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.key.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.value.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"value.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.value.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"value.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"key.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms"</span><span class="p">:</span><span class="w"> </span><span class="s2">"unwrap"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms.unwrap.type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"io.debezium.transforms.ExtractNewRecordState"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms.unwrap.add.source.fields"</span><span class="p">:</span><span class="w"> </span><span class="s2">"ts_ms"</span><span class="p">,</span><span class="w">
</span><span class="nl">"tombstones.on.delete"</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="p">}</span></code></pre></figure>

<h3 id="install-the-connector">Install the Connector:</h3>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="syntax"><code>curl -X POST -H "Accept: application/json" -H "Content-Type: application/json" http://localhost:8083/connectors -d @mysql.json
</code></pre></div></div>

<h3 id="ingest-the-master-binlog-info">Ingest the master binlog info:</h3>

<p>Get the last read binlog info from the Kafka topic and manually add the masterâ€™s binlog into it.</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="syntax"><code>kafkacat -b localhost:9092 -C -t connect-offsets  -f 'Partition(%p) %k %s\n'

Partition(1) ["mysql-connector-db01",{"server":"mysql-db01"}] {"file":"mysql-bin.000004","pos":89114,"gtids":"4ac96fbf-3c4b-11ea-8ea0-4201ac180012:1-19,c3c1d467-3bee-11ea-907b-4201ac18000c:1-36003"}
</code></pre></div></div>

<p>Now replica the binlog file name, position,  UUID. (sometimes youâ€™ll get multiple UUID, so remove everything, just keep the masterâ€™s UUID)</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="syntax"><code>echo '["mysql-connector-db01",{"server":"mysql-db01"}]|{"file":"mysql-bin.000001","pos":10259755,"gtids":"c3c1d467-3bee-11ea-907b-4201ac18000c:1-36003"}' | kafkacat -P -b localhost -t connect-offsets -K \| -p 1
</code></pre></div></div>

<p>Check this data in <code class="language-html highlighter-rouge">connect-offsets</code></p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafka-console-consumer <span class="nt">--bootstrap-server</span> localhost:9092 <span class="nt">--topic</span> connect-offsets <span class="nt">--from-beginning</span>
<span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"mysql-bin.000004"</span>,<span class="s2">"pos"</span>:67739,<span class="s2">"gtids"</span>:<span class="s2">"4ac96fbf-3c4b-11ea-8ea0-4201ac180012:1-237,c3c1d467-3bee-11ea-907b-4201ac18000c:1-36003"</span><span class="o">}</span>

<span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"mysql-bin.000001"</span>,<span class="s2">"pos"</span>:10259755,<span class="s2">"gtids"</span>:<span class="s2">"c3c1d467-3bee-11ea-907b-4201ac18000c:1-36003"</span><span class="o">}</span></code></pre></figure>

<h3 id="update-the-connector">Update the connector:</h3>

<p>Use the below Config file to update it. Make sure the <code class="language-html highlighter-rouge">database.history.kafka.topic</code> will be a new topic and<code class="language-html highlighter-rouge">snapshot.mode</code> must be <code class="language-html highlighter-rouge">SCHEMA_ONLY_RECOVERY</code>. And the update the MySQL details, kafka.</p>

<figure class="highlight"><pre><code class="language-json" data-lang="json"><span class="p">{</span><span class="w">
</span><span class="nl">"connector.class"</span><span class="p">:</span><span class="w"> </span><span class="s2">"io.debezium.connector.mysql.MySqlConnector"</span><span class="p">,</span><span class="w">
</span><span class="nl">"snapshot.locking.mode"</span><span class="p">:</span><span class="w"> </span><span class="s2">"none"</span><span class="p">,</span><span class="w">
</span><span class="nl">"tasks.max"</span><span class="p">:</span><span class="w"> </span><span class="s2">"3"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.history.kafka.topic"</span><span class="p">:</span><span class="w"> </span><span class="s2">"master-schema-changes.mysql"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms"</span><span class="p">:</span><span class="w"> </span><span class="s2">"unwrap"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.key.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms.unwrap.add.source.fields"</span><span class="p">:</span><span class="w"> </span><span class="s2">"ts_ms"</span><span class="p">,</span><span class="w">
</span><span class="nl">"tombstones.on.delete"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms.unwrap.type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"io.debezium.transforms.ExtractNewRecordState"</span><span class="p">,</span><span class="w">
</span><span class="nl">"value.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.whitelist"</span><span class="p">:</span><span class="w"> </span><span class="s2">"bhuvi"</span><span class="p">,</span><span class="w">
</span><span class="nl">"key.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.user"</span><span class="p">:</span><span class="w"> </span><span class="s2">"root"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.server.id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.history.kafka.bootstrap.servers"</span><span class="p">:</span><span class="w"> </span><span class="s2">"10.128.0.12:9092"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.server.name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.port"</span><span class="p">:</span><span class="w"> </span><span class="s2">"3306"</span><span class="p">,</span><span class="w">
</span><span class="nl">"key.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.key.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.hostname"</span><span class="p">:</span><span class="w"> </span><span class="s2">"172.24.0.13"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.password"</span><span class="p">:</span><span class="w"> </span><span class="s2">"****"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.value.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-connector-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"value.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.value.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"snapshot.mode"</span><span class="p">:</span><span class="w"> </span><span class="s2">"SCHEMA_ONLY_RECOVERY"</span><span class="w">
</span><span class="p">}</span></code></pre></figure>

<p>Once its updated, check the status of the connector.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">curl GET localhost:8083/connectors/mysql-connector-db01/status

<span class="o">{</span>
<span class="s2">"name"</span>: <span class="s2">"mysql-connector-db01"</span>,
<span class="s2">"connector"</span>: <span class="o">{</span>
<span class="s2">"state"</span>: <span class="s2">"RUNNING"</span>,
<span class="s2">"worker_id"</span>: <span class="s2">"10.128.0.14:8083"</span>
<span class="o">}</span>,
<span class="s2">"tasks"</span>: <span class="se">\[</span>
<span class="o">{</span>
<span class="s2">"id"</span>: 0,
<span class="s2">"state"</span>: <span class="s2">"RUNNING"</span>,
<span class="s2">"worker_id"</span>: <span class="s2">"10.128.0.14:8083"</span>
<span class="o">}</span>
<span class="se">\]</span>,
<span class="s2">"type"</span>: <span class="s2">"source"</span>
<span class="o">}</span></code></pre></figure>

<p>Check the binlog inforation from the connect-offset topic.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafka-console-consumer <span class="nt">--bootstrap-server</span> localhost:9092 <span class="nt">--topic</span> connect-offsets <span class="nt">--from-beginning</span>

<span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"mysql-bin.000004"</span>,<span class="s2">"pos"</span>:67739,<span class="s2">"gtids"</span>:<span class="s2">"4ac96fbf-3c4b-11ea-8ea0-4201ac180012:1-237,c3c1d467-3bee-11ea-907b-4201ac18000c:1-36003"</span><span class="o">}</span>
<span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"mysql-bin.000001"</span>,<span class="s2">"pos"</span>:10259755,<span class="s2">"gtids"</span>:<span class="s2">"c3c1d467-3bee-11ea-907b-4201ac18000c:1-36003"</span><span class="o">}</span>

<span class="o">{</span><span class="s2">"ts_sec"</span>:1579610781,<span class="s2">"file"</span>:<span class="s2">"mysql-bin.000001"</span>,<span class="s2">"pos"</span>:10263525,<span class="s2">"gtids"</span>:<span class="s2">"c3c1d467-3bee-11ea-907b-4201ac18000c:1-36016"</span>,<span class="s2">"row"</span>:1,<span class="s2">"server_id"</span>:128423640,<span class="s2">"event"</span>:2<span class="o">}</span></code></pre></figure>

<p>You can see the thrid line which is nothing but the 6th row that we inserted on master after disabling the replication. Now insert one more row and see whether is read by the connector or not.</p>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="n">mysql</span><span class="o">&gt;</span> <span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafka-console-consumer <span class="nt">--bootstrap-server</span> localhost:9092 <span class="nt">--topic</span> connect-offsets <span class="nt">--from-beginning</span>
<span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"mysql-bin.000004"</span>,<span class="s2">"pos"</span>:67739,<span class="s2">"gtids"</span>:<span class="s2">"4ac96fbf-3c4b-11ea-8ea0-4201ac180012:1-237,c3c1d467-3bee-11ea-907b-4201ac18000c:1-36003"</span><span class="o">}</span>
<span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"mysql-bin.000001"</span>,<span class="s2">"pos"</span>:10259755,<span class="s2">"gtids"</span>:<span class="s2">"c3c1d467-3bee-11ea-907b-4201ac18000c:1-36003"</span><span class="o">}</span>

<span class="o">{</span><span class="s2">"ts_sec"</span>:1579610781,<span class="s2">"file"</span>:<span class="s2">"mysql-bin.000001"</span>,<span class="s2">"pos"</span>:10263525,<span class="s2">"gtids"</span>:<span class="s2">"c3c1d467-3bee-11ea-907b-4201ac18000c:1-36016"</span>,<span class="s2">"row"</span>:1,<span class="s2">"server_id"</span>:128423640,<span class="s2">"event"</span>:2<span class="o">}</span>

<span class="o">{</span><span class="s2">"ts_sec"</span>:1579612311,<span class="s2">"file"</span>:<span class="s2">"mysql-bin.000001"</span>,<span class="s2">"pos"</span>:10350729,<span class="s2">"gtids"</span>:<span class="s2">"c3c1d467-3bee-11ea-907b-4201ac18000c:1-36322"</span>,<span class="s2">"row"</span>:1,<span class="s2">"server_id"</span>:128423640,<span class="s2">"event"</span>:2<span class="o">}</span></code></pre></figure>

<h3 id="check-the-data-in-the-tables-data-from-kafaka">Check the data in the tableâ€™s data from Kafaka</h3>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafka-console-consumer <span class="nt">--bootstrap-server</span> localhost:9092 <span class="nt">--topic</span> mysql-db01.bhuvi.rohi <span class="nt">--from-beginning</span>
<span class="o">{</span><span class="s2">"id"</span>:1,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:0<span class="o">}</span>
<span class="o">{</span><span class="s2">"id"</span>:2,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:0<span class="o">}</span>
<span class="o">{</span><span class="s2">"id"</span>:3,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:0<span class="o">}</span>
<span class="o">{</span><span class="s2">"id"</span>:4,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:0<span class="o">}</span>
<span class="o">{</span><span class="s2">"id"</span>:5,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:0<span class="o">}</span>
<span class="o">{</span><span class="s2">"id"</span>:6,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:1579610781000<span class="o">}</span>
<span class="o">{</span><span class="s2">"id"</span>:7,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:1579612311000<span class="o">}</span></code></pre></figure>

<h3 id="debezium-series-blogs">Debezium Series blogs:</h3>

<ol>
  <li><a href="https://thedataguy.in/build-production-grade-debezium-with-confluent-kafka-cluster/">Build Production Grade Debezium Cluster With Confluent Kafka</a></li>
  <li><a href="https://thedataguy.in/monitor-debezium-mysql-connector-with-prometheus-and-grafana/">Monitor Debezium MySQL Connector With Prometheus And Grafana</a></li>
  <li><a href="https://thedataguy.in/debezium-mysql-snapshot-from-read-replica-with-gtid/">Debezium MySQL Snapshot From Read Replica With GTID</a></li>
  <li><a href="https://thedataguy.in/debezium-mysql-snapshot-from-read-replica-and-resume-from-master/">Debezium MySQL Snapshot From Read Replica And Resume From Master</a></li>
  <li><a href="https://thedataguy.in/debezium-mysql-snapshot-for-aws-rds-aurora-from-backup-snaphot/">Debezium MySQL Snapshot For AWS RDS Aurora From Backup Snaphot</a></li>
  <li><a href="https://medium.com/searce/realtime-cdc-from-mysql-using-aws-msk-with-debezium-28da5a4ca873">RealTime CDC From MySQL Using AWS MSK With Debezium</a></li>
</ol>
:ET